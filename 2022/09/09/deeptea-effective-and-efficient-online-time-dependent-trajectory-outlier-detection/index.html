<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>DeepTEA: Effective and Efficient Online Time-dependent Trajectory Outlier Detection - Davidham&#039;s blog</title><meta description="PVLDB 2022. DeepTEA: Effective and Efficient Online Time-dependent Trajectory Outlier  Detection"><meta property="og:type" content="blog"><meta property="og:title" content="DeepTEA: Effective and Efficient Online Time-dependent Trajectory Outlier Detection"><meta property="og:url" content="https://davidham3.github.io/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/"><meta property="og:site_name" content="Davidham&#039;s blog"><meta property="og:description" content="PVLDB 2022. DeepTEA: Effective and Efficient Online Time-dependent Trajectory Outlier  Detection"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://davidham3.github.io/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Fig1.jpg"><meta property="og:image" content="https://davidham3.github.io/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Fig2.jpg"><meta property="og:image" content="https://davidham3.github.io/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Algo1.jpg"><meta property="og:image" content="https://davidham3.github.io/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Fig3.jpg"><meta property="og:image" content="https://davidham3.github.io/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Algo2.jpg"><meta property="article:published_time" content="2022-09-09T14:24:04.000Z"><meta property="article:modified_time" content="2022-09-12T15:48:44.573Z"><meta property="article:author" content="Davidham"><meta property="article:tag" content="deep learning"><meta property="article:tag" content="trajectory"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Fig1.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://davidham3.github.io/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/"},"headline":"Davidham's blog","image":["https://davidham3.github.io/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Fig1.jpg","https://davidham3.github.io/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Fig2.jpg","https://davidham3.github.io/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Algo1.jpg","https://davidham3.github.io/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Fig3.jpg","https://davidham3.github.io/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Algo2.jpg"],"datePublished":"2022-09-09T14:24:04.000Z","dateModified":"2022-09-12T15:48:44.573Z","author":{"@type":"Person","name":"Davidham"},"description":"PVLDB 2022. DeepTEA: Effective and Efficient Online Time-dependent Trajectory Outlier  Detection"}</script><link rel="canonical" href="https://davidham3.github.io/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/"><link rel="icon" href="/blog/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/"><img src="/blog/img/logo.svg" alt="Davidham&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">Home</a><a class="navbar-item" href="/blog/archives">Archives</a><a class="navbar-item" href="/blog/categories">Categories</a><a class="navbar-item" href="/blog/tags">Tags</a><a class="navbar-item" href="/blog/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2022-09-09T14:24:04.000Z" title="2022-09-09T14:24:04.000Z">2022-09-09</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">34 minutes read (About 5101 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">DeepTEA: Effective and Efficient Online Time-dependent Trajectory Outlier Detection</h1><div class="content"><p>PVLDB 2022. <a href="https://www.vldb.org/pvldb/vol15/p1493-han.pdf">DeepTEA: Effective and Efficient Online Time-dependent Trajectory Outlier<br>  Detection</a><br><a id="more"></a></p>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>研究异常轨迹检测，目的是提取道路中车辆的异常移动。可以帮助理解交通行为，识别出租车欺诈。由于交通状况在不同时间不同地点会发生变化，所以这个问题具有挑战。本文提出了Deep-probabilistic-based time-dependent anomaly detection algorithm (DeepTEA)。使用深度学习方法从大量轨迹里面获得time-dependent outliners，可以处理复杂的交通状况，并精确地检测异常现象。本文还提出了一个快速的近似方法，为了在实时环境下捕获到异常行为。相比SOTA方法，本文方法提升了17.52%，并且可以处理百万计的轨迹数据。</p>
<h1 id="2-Problem-Definition"><a href="#2-Problem-Definition" class="headerlink" title="2. Problem Definition"></a>2. Problem Definition</h1><p>Definition 1(Trajectory). 轨迹点$p_{t_i}$是一个三元组$(t_i, x, y)$，分别是时间戳、纬度、经度。轨迹$T$是一个轨迹点的有序序列$<p_{t_1}, \dots, p_{t_i}, p_{t_n}>$，其中$t_1 &lt; \dots &lt; t_i &lt; \dots &lt; t_n$。</p_{t_1},></p>
<p>轨迹异常检测分为两类，一类是只考虑与正常路线不同的异常轨迹。另一种是考虑与time-dependent的正常路线不同的异常轨迹。</p>
<p>Definition 2(Time-dependent Trajectory Outlier)。给一条轨迹$T$，起点$S_T$，终点是$D_T$，还有travel时间，一个time-dependent轨迹异常定义为：相同的$S_T$和$D_T$以及相同的出发、到达时间下的轨迹里面，一个很稀有的、不同于其他轨迹的轨迹。</p>
<center><img src="/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Fig1.jpg" class title="Figure1"></center>

<p>举例，如果一个轨迹在2016年10月1日的上午10点出发，11点到达，那么一条稀有的轨迹且和相同时间相同OD的轨迹不同的轨迹就是这个Time-dependent Trajectory Outlier.</p>
<p>Problem 1(Online Time-dependent Trajectory Outlier Detection)。给定一条正在前进的轨迹$T$，实时计算并更新这条轨迹是时间依赖的异常轨迹的概率。</p>
<h1 id="3-The-DeepTEA-Model"><a href="#3-The-DeepTEA-Model" class="headerlink" title="3. The DeepTEA Model"></a>3. The DeepTEA Model</h1><h2 id="3-1-Framework"><a href="#3-1-Framework" class="headerlink" title="3.1 Framework"></a>3.1 Framework</h2><center><img src="/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Fig2.jpg" class title="Figure2"></center>

<p>给定轨迹$T$，在旅行过程中推算latent traffic pattern $q(z \mid T)$。轨迹观测值 $\tau$ 反映时间依赖的轨迹转移，可以在 inference network 里面用来建模latent time-dependent route $r$。之后，time-dependent route $r$用来生成轨迹观测值$\tau$。</p>
<h2 id="3-2-Latent-Traffic-Pattern-Inference"><a href="#3-2-Latent-Traffic-Pattern-Inference" class="headerlink" title="3.2 Latent Traffic Pattern Inference"></a>3.2 Latent Traffic Pattern Inference</h2><p>latent traffic pattern $z$，表示旅途过程中的动态交通状况，比如 $\{\text{smooth} \rightarrow \text{congested} \rightarrow \text{smooth} \}$，或者$\{\text{congested} \rightarrow \text{smooth} \}$。</p>
<h3 id="3-2-1-Challenges"><a href="#3-2-1-Challenges" class="headerlink" title="3.2.1 Challenges"></a>3.2.1 Challenges</h3><p>给定轨迹 $T$，我们想基于 $T$ 的空间转移，推算出 latent traffic pattern $q(z \mid T)$。举个例子，一个远距离的移动表明当时的交通状况是通畅的。但是一个轨迹 $T$ 可能表示一些随机行为，比如停车休息，这种行为不能表明当时的交通状况。这是在表示实际交通模式时的第一个挑战。第二个挑战是交通状态在不同的地方，不同的时间是不同的，动态的。同一时间，不同OD也是不一样的。而且在整个旅途中的交通状态变化也是剧烈的。可能开始的时候顺畅，结束的时候拥堵。捕获交通状态很重要，因为它对时间依赖的正常路径影响很大。</p>
<h3 id="3-2-2-Design"><a href="#3-2-2-Design" class="headerlink" title="3.2.2 Design"></a>3.2.2 Design</h3><p>为了解决第一个挑战，我们从时间 $t_i$ 的一组轨迹 $\{ T_{t_i} \}$ 里面学习latent traffic pattern $z$，而不是单条轨迹 $T$。这里我们用 time point series 表示旅行时间。为了从 $\{ T_{t_i} \}$ 里面很好地组织交通信息，我们使用一个 map grid matrix $Z_{t_i}$，这里面每个单元表示平均速度，用这个对 $t_i$ 的交通状态建模。从图2可以看出，红色表示速度低，表示拥堵。绿色表示畅通。黄色表示即将拥堵，平均速度介于红绿之间。为了解决同一时间不同位置交通状态的多样性，我们用CNN建模。对于没有车辆的区域，CNN可以从有车辆的单元学到信息，而不是将他们表示为缺失值。因为实时状态下交通状况变得很频繁，我们用RNN捕获这种不断变化的动态性，解决第二个挑战。交通状态的变化可以通过RNN很好的建模。然后我们用一个高斯分布和RNN的隐藏状态，推算 latent traffic pattern $z$。CNN+RNN选用了 Convolutional LSTM。</p>
<p>我们用上面的随时间变化的动态交通状态来推算latent traffic pattern $z$。这里的想法是交通状态会因为复杂的实时特征发生变化，比如信号灯、事故、早晚高峰。因此，我们在DeepTEA里面会随时间变化更新$Z$，表示为$Z_{t_i}$，表示轨迹点$p_{t_i}$在时间$t_i$的交通状态。我们会从实际交通状况$Z = \{ Z_{t_i}, Z_{t_{i+1}}, \dots, Z_{t_{i+n}} \}$里面推算latent traffic pattern $z$。这里面的交通状况对应的时间分别是对应轨迹点$\{ p_t, p_{t+1}, \dots, p_{t_{i+n}} \}$的时间。对于真实交通状况$Z$，我们可以得到轨迹$T$经过的时间的平均速度。换句话说就是，真实交通状况$Z_{t_i}$是一个平均速度矩阵，它包含了整个城市在$t_i$的移动状态。如果两个轨迹点之间的时间差很小，那么$Z_{t_i}$和$Z_{t_{i+1}}$可能会很相似。这样的话，我们需要把速度按时段提前聚合起来，就取平均速度，比如10分钟的时段，而不再使用时间点。为了减轻稀疏的问题，我们使用CNN将有车辆的位置的信息传播到没有车辆没数据的位置上。为了捕获不同时段的动态变化，我们用RNN建模时间维度的交通转移。这样，spatial traffic correlation和temporal transition通过$f_1(Z)$来捕获：</p>
<script type="math/tex; mode=display">\tag{1}
f_1(Z) = \text{RNN}(\text{CNN}(Z)),</script><p>这里函数$f_1(\cdot)$是一个CNN+RNN，CNN对每个$Z_i$都使用，然后用RNN对他们建模，捕获traffic transition。</p>
<p>为了让模型具有生成能力，并且对交通状态的不确定性建模，在给定实际交通状态$Z$的时候，我们用高斯分布对latent traffic pattern $z$建模，可以用来在给定轨迹$T$时近似latent traffic pattern $z$的分布，如公式2所示。我们将参数记为$\phi$，</p>
<script type="math/tex; mode=display">\tag{2}
q_\phi(z \mid T) \coloneqq q_\phi(z \mid Z) = \mathcal{N}(\mu_Z, \text{diag}(\sigma^2_Z)),</script><p>均值$\mu_Z$和标准差$\sigma_Z$通过MLP函数 $g_1(f_1(Z))$得到，参数是$\phi = \{ f_1(\cdot), g_1(\cdot) \}$。</p>
<p>这种方式在给定轨迹$T$的时候可以很好的推断出latent traffic pattern $z$。在训练阶段，参数$\phi$可以学到如何捕获latent traffic pattern $z$，而且能表示交通状态的多样性和动态性。</p>
<h2 id="3-3-Latent-Time-dependent-Route-Inference"><a href="#3-3-Latent-Time-dependent-Route-Inference" class="headerlink" title="3.3 Latent Time-dependent Route Inference"></a>3.3 Latent Time-dependent Route Inference</h2><h3 id="3-3-1-Challenges"><a href="#3-3-1-Challenges" class="headerlink" title="3.3.1 Challenges"></a>3.3.1 Challenges</h3><p>轨迹$T$不仅可以表示位置信息，还可以表示两个轨迹点之间转移的latent traffic pattern $z$。相比只最大化位置信息的似然，对位置和latent traffic pattern $z$同时做更informative，因为它可以反映在时间依赖的交通状态下的轨迹转移。</p>
<h3 id="3-3-2-Design"><a href="#3-3-2-Design" class="headerlink" title="3.3.2 Design"></a>3.3.2 Design</h3><p>一条轨迹 $T$ 不仅能反映位置 $p_{t_i}$，还能基于两个连续轨迹点 $p_{t_{i-1}}$ 和 $p_{t_i}$ 之间的转移，传递出 latent traffic pattern $z$。这里我们用 $o(p_{t_i}, z)$ 表示轨迹 $T$ 背后的观测值 $\tau_i$。这里希望用一个神经网络处理观测值 $p_{t_i}$ 和 $z$：</p>
<script type="math/tex; mode=display">\tag{3}
\tau_i = o(p_{t_i}, z) = f_2(p_{t_i}, z) = \text{NN}(p_{t_i}, z),</script><p>我们使用一个神经网络学习 latent traffic pattern $z$ 的观测值 $p_{t_i}$：</p>
<script type="math/tex; mode=display">\tag{4}
\text{NN}(p_{t_i}, z) = W p_{t_i} + Q z,</script><p>$\text{NN}$的参数是$W$和$Q$。</p>
<p>然后，我们学习一条轨迹 $T$ 经过的 latent time-dependent route $r$。我们解释过，轨迹 $T$ 不仅能表示轨迹点 $p_{t_i}$ 的位置信息，还能指明两个轨迹点之间转移的 latent traffic pattern $z$。latent time-dependent route $r$ 的含义可以解释为：高峰时间段城市路段的交通状态是拥堵的，驾驶员通常会上高速，因为那里会畅通。</p>
<p>轨迹 $T$ 经过的 latent time-dependent route $r$ 的表示为：</p>
<script type="math/tex; mode=display">\tag{5}
r_T \sim q_\gamma (r \mid T),</script><p>$\gamma$ 是推测 latent time-dependent route $r$ 时的参数。</p>
<p>基于之前的轨迹点和 latent traffic pattern $z$，我们可以用RNN获得轨迹观测值之间的转移，RNN记为 $f_3$，这里使用GRU：</p>
<script type="math/tex; mode=display">\tag{6}
h_i = f_3 (h_{i-1}, \tau_i),</script><p>$h_{i-1}$ 是之前观测值 $\tau_{i-1}$ 的隐藏状态，也就是轨迹点 $p_{t_{i-1}}$ 带着 latent traffic pattern $z$。</p>
<p>对于轨迹观测值的不确定性，我们通过高斯分布建模 $q_\gamma (r \mid T)$：</p>
<script type="math/tex; mode=display">\tag{7}
q_\gamma (r \mid T) = \mathcal{N} (\mu_T, \text{diag}(\sigma^2_T)),</script><p>我们用一个神经网络 $g_3(h_n)$ 来学习均值和标准差。</p>
<p>为了在 latent traffic pattern 里面区分正常的轨迹转移和异常的轨迹转移，需要设计一个模块对轨迹里 latent time-dependent normal route建模，这里 $z$ 会提供 time-dependent traffic 信息。使用高斯分布：</p>
<script type="math/tex; mode=display">\tag{8}
p_\gamma (r \mid k, z) = \mathcal{N}(\mu_r, \text{diag}(\sigma^2_r)),</script><p>$k$ 表示 latent time-dependent route 的类型，服从多项式分布：</p>
<script type="math/tex; mode=display">\tag{9}
p_\gamma (k) = \text{Mult} (\pi),</script><p>$\pi$ 是多项式分布的参数。然后，趋近 $q_\gamma (r \mid T)$ 的均值的 latent time-dependent route 是time-dependent normal route。</p>
<p>然后，推断网络可以从给定的轨迹 $T$ 里面推算 latent time-dependent route $r$，latent time-dependent route type $k$，还有 latent traffic pattern $z$ 为 $q_{\gamma,\phi}(r, k, z \mid T)$。通过使用 mean-field approximation，可以分解为：</p>
<script type="math/tex; mode=display">\tag{10}
q_{\gamma,\phi}(r, k, z \mid T) = q_\gamma(r \mid T) \ q_\phi(z \mid T) \ q_\gamma (k \mid T),</script><p>$q_\gamma (k \mid T)$ 可以转换为在给定 轨迹 $T$ 经过 latent time-dependent route $r$ 的条件下，route type $k$ 的分布：</p>
<script type="math/tex; mode=display">\tag{11}
q_\gamma (k \mid T) \coloneqq p_\gamma (k \mid r_T) = \frac{p_\gamma (k) p_\gamma (r_T \mid k)}{\sum^K_{i=1} p_\gamma (k_i) p_\gamma (r_T \mid k_i)},</script><p>$K$ 是一个超参数，表示 route 类型的个数。</p>
<p>因此，推断网络可以从轨迹 $T$ 的观测值 $o(p_{t_i}, z)$ 推断出 latent time-dependent route $r$。$\gamma = \{ f_2(\cdot), f_3(\cdot), g_3(\cdot), \pi, \mu_r, \sigma_r \}$ 这些都是参数。</p>
<h2 id="3-4-Trajectory-Observation-Generation"><a href="#3-4-Trajectory-Observation-Generation" class="headerlink" title="3.4 Trajectory Observation Generation"></a>3.4 Trajectory Observation Generation</h2><p>生成轨迹观测值的目标是给定 latent time-dependent route $r$，time-dependent route type $k$ 和 latent traffic pattern $z$ 时，最大化生成轨迹观测值 $\tau_i$ 的概率，也就是 $o(p_{t_i}, z)$。这个概率记为 $p_\theta (T \mid r, z, k)$，$\theta$ 表示用于生成过程的参数。从对称的角度来看，我们用RNN来生成轨迹观测值 $\tau_i$，也就是 $o(p_{t_i}, z)$：</p>
<script type="math/tex; mode=display">\tag{12}
\begin{align}
\eta_i &= f_4 (\tau_i, \eta_{i-1}) \\
&= f_4(o(p_{t_i}, z), \eta_{i-1}) \\
&= \text{RNN} (o(p_{t_i}, z), \eta_{i-1}), i = 1, 2, \dots, n, \ and \ \eta_o = r,
\end{align}</script><p>RNN的起始输入是 $\eta_0$。从 $\eta_1$ 开始，输入变成上一个隐藏状态 $\eta_{i-1}$ 和轨迹观测值 $o(p_{t_i}, z)$。因此，观测值 $\tau_i$，也就是 $p_{t_i}$ 在 latent traffic pattern $z$ 的时候，可以通过下面的公式生成：</p>
<script type="math/tex; mode=display">\tag{13}
\begin{align}
\tau_i &= o(p_{t_i}, z) \sim p_\theta (o(p_{t_i}, z) \mid o(p_{1:i-1}, z), r) \\
&= p_\theta(\tau \mid \eta_{i-1}) \\
&= \text{Mult}(\text{softmax}(g_4 (\eta_{i-1}))),
\end{align}</script><p>$g_4(\cdot)$是一个函数，把输出映射到网格的个数。softmax 用来把概率的和变成1。然后轨迹观测值 $\tau_i$ 可以通过多项式分布生成。</p>
<p>因此，轨迹观测值 $\tau_i$，也就是 $o(p_{t_i}, z)$，可以基于 latent time-dependent route $r$，route type $k$ 和 latent traffic pattern $z$ 生成。我们给生成用的参数记为 $\theta = \{ f_4(\cdot), g_4(\cdot) \}$。这些参数会在训练的过程中学到。</p>
<h2 id="3-5-Optimization"><a href="#3-5-Optimization" class="headerlink" title="3.5 Optimization"></a>3.5 Optimization</h2><p>我们上面讲了，轨迹观测值不仅能反映位置信息，还能基于两个连续的轨迹点的转移传递出 latent traffic pattern。因此，目标函数是最大化观测到的轨迹的边缘对数似然：</p>
<script type="math/tex; mode=display">\tag{14}
\log p_\theta(T^{(1)}, T^{(2)}, \dots, T^{(N)}) \coloneqq \log p_\theta (\tau^{(1)}, \tau^{(2)}, \dots, \tau^{(N)}).</script><p>我们通过最大化ELBO来优化上面的边缘对数似然函数：</p>
<script type="math/tex; mode=display">\tag{15}
\log p_\theta (T) \geq \text{ELBO} = \mathcal{L}(\phi, \gamma, \theta; T).</script><p>轨迹 $T$ 的边缘对数似然函数的 ELBO 通过下面的公式计算：</p>
<script type="math/tex; mode=display">\tag{16}
\begin{align}
\mathcal{L}(\phi, \gamma, \theta; T) &= \mathbb{E}_{q_{\gamma, \phi}(r, k, z \mid T)}[ \log \frac{p_{\phi, \gamma, \theta}(r, k, z, T)}{q_{\gamma, \theta}(r, k, z \mid T)}] \\
&= - \mathbb{E}_{q_\gamma(r \mid T)} D_{KL} (q_\gamma (k \mid T) \Vert p_\gamma (k)) \\
& - \mathbb{E}_{q_\gamma (k \mid T)} D_{KL} ( q_\gamma (r \mid T) \Vert p_\gamma (r \mid k, z)) \\
& - D_{KL} (q_\phi (z \mid T) \Vert p_\phi(z)) + \mathbb{E}_{q_{\gamma, \phi}(r, k, z \mid T)} \log p_\theta (T \mid r, z, k),
\end{align}</script><p>其中，$p_\theta(z)$ 是 latent traffic pattern $z$ 的先验概率。生成网络 $\log p_\theta(T \mid r, z, k)$ 可以通过下面公式计算：</p>
<script type="math/tex; mode=display">\tag{17}
\log p_\theta (T \mid r, z, k) = \sum^n_{i=1} \log p_\theta (\tau_i \mid \tau_{1: i-1}, r, z, k)</script><p>整个训练过程的算法如算法1所示。在训练过程中，模型参数通过优化轨迹 $T$ 的 ELBO 来学习。然后这些学到的参数会用于 online anomaly detection，后面会介绍。</p>
<center><img src="/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Algo1.jpg" class title="Algo1"></center>

<h2 id="3-6-Complexity-Analysis"><a href="#3-6-Complexity-Analysis" class="headerlink" title="3.6 Complexity Analysis"></a>3.6 Complexity Analysis</h2><p>训练 DeepTEA 的复杂度是 $O(N \cdot (d_{Z_1} d_{Z_2} \bar{V} + \bar{n}))$，$N$ 是轨迹数，$d_{Z_1}$ 和 $d_{Z_2}$ 是 $Z$ 的大小，$\bar{V}$ 是时间间隔的平均个数，$\bar{n}$ 是轨迹的平均长度。</p>
<h1 id="Online-Trajectory-Outlier-Detection-by-DeepTEA"><a href="#Online-Trajectory-Outlier-Detection-by-DeepTEA" class="headerlink" title="Online Trajectory Outlier Detection by DeepTEA"></a>Online Trajectory Outlier Detection by DeepTEA</h1><p>基于算法1学习得到的参数，当下一个轨迹观测值 $\tau_{i+1}$ 实时过来的时候，异常分数会实时更新。这个过程要快。而且直到轨迹完成，这个异常分数都要更新。</p>
<h2 id="4-1-Online-Detection-by-Generation"><a href="#4-1-Online-Detection-by-Generation" class="headerlink" title="4.1 Online Detection by Generation"></a>4.1 Online Detection by Generation</h2><p>图3展示了在线异常轨迹检测的步骤。</p>
<center><img src="/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Fig3.jpg" class title="Figure3"></center>

<p>我们通过学到的网络生成观测到的轨迹来检测异常。latent time-dependent route 的分布 $q_\gamma (r \mid T)$ 可以通过参数 $\gamma$ 来计算。latent traffic pattern $z$ 可以通过参数 $\phi$ 和 $Z$ 获得。给定 $q_\gamma (r \mid T)$ 里面第 $k$ 个均值 $u_k$，我们用 RNN 生成轨迹观测值：</p>
<script type="math/tex; mode=display">\tag{18}
\eta_i = f_4(\tau_i, \eta_{i-1}) = \text{RNN} (\tau_i, \eta_{i - 1}), i = 1, 2, \dots, n, \text{and} \ \eta_0 = u_k,</script><p>RNN的起始输入是 $\eta_0$，这里设置为 $u_k$。从 $\eta_1$ 开始，输入标称隐藏状态 $\eta_{i-1}$ 和轨迹观测值 $\tau_i$，即 $o(p_{t_i}, z)$。因此 $\tau_{i+1}$ 可以用下面的公式生成：</p>
<script type="math/tex; mode=display">\tag{19}
p_\theta (\tau_{i+1} \mid \tau_{i:i}, u_k) = \text{softmax}(g_4 (\eta_{i-1})),</script><p>$g_4(\cdot)$ 是用来把输出映射到网格数的函数。</p>
<p>给定学到的 $q_\gamma (r \mid T)$ 和 latent traffic pattern $z$，轨迹 $T$ 的实时异常分数 $s_a(\tau_{i:i})$ 可以计算为 1 - 生成轨迹观测值 $\tau_{i:i}$ 的似然，即 $\{ \tau_1 \rightarrow \tau_2 \rightarrow \dots \tau_i \}$：</p>
<script type="math/tex; mode=display">\tag{20}
s_a(\tau_{i:i}) = 1 - \arg \max_k \exp [\frac{\sum^n_{i=1} \log p_\theta (\tau_i \mid \tau_{1:i-1}, u_k)}{n}]</script><p>在线上场景下，给定之前的轨迹观测值 $\tau_{i:i}$，下一个轨迹观测值的异常分数可以通过之前这个数来计算：</p>
<script type="math/tex; mode=display">\tag{21}
s_a(\tau_{i:i+1}) = 1 - \arg \max_k \exp [\frac{\log p_\theta (\tau_{1:i} \mid u_k) p_\theta(\tau_{i+1} \mid \tau_{1:i}, u_k)}{i + 1}]</script><center><img src="/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/Algo2.jpg" class title="Algo2"></center>

<p>算法2是在线检测的过程。输入是轨迹 $T$，参数是从算法1学到的。对于新来的轨迹观测值 $\tau_{i+1}$，如果 latent traffic pattern $z$ 变了，那我们就更新 $z$。然后基于 $\tau_{1:i}$ 计算 $\tau_{1:i+1}$。最后返回异常分数。</p>
<h2 id="4-2-Complexity-Analysis"><a href="#4-2-Complexity-Analysis" class="headerlink" title="4.2 Complexity Analysis"></a>4.2 Complexity Analysis</h2><p>整个检测的复杂度是 $\mathcal{O}(d_{Z_1} d_{Z_2})$，$d_{Z_1}$ 和 $d_{Z_2}$ 是 $Z$ 的大小。</p>
<h1 id="5-The-DeepTEA-A-Model-Approximate-Online-Detection"><a href="#5-The-DeepTEA-A-Model-Approximate-Online-Detection" class="headerlink" title="5 The DeepTEA-A Model: Approximate Online Detection"></a>5 The DeepTEA-A Model: Approximate Online Detection</h1><h2 id="5-1-Approximation-Algorithm"><a href="#5-1-Approximation-Algorithm" class="headerlink" title="5.1 Approximation Algorithm"></a>5.1 Approximation Algorithm</h2><h3 id="5-1-1-Challenge"><a href="#5-1-1-Challenge" class="headerlink" title="5.1.1 Challenge"></a>5.1.1 Challenge</h3><p>基于 $\tau_{1:i}$ 的异常分数更新依赖 $t_{i+1}$ 的交通状态矩阵 $Z$，如果路网很大，这里耗时会长。</p>
<h3 id="5-1-2-Design"><a href="#5-1-2-Design" class="headerlink" title="5.1.2 Design"></a>5.1.2 Design</h3><p>受 GM-VSAE 的启发，本文提出了近似算法。使用 $\tau_1$ 的时段的交通状态矩阵 $Z$ 作为整个 trip 过程的交通状况的近似。这样，$Z$ 只要在第一个轨迹观测值 $\tau_1$ 的时候算一下就好了。online 更新的时候就不需要再算这个了。</p>
<p>给定一个起点 $S_T$ 和终点 $D_T$，从 $q(k \mid S_T, D_T, z_{S_T})$ 这里面取出最优的 latent route type $k$ 来近似最有 latent route pattern $u_k$，这需要从 $q_\gamma (r \mid T)$ 的 $k$ 个均值里面找，$Z_{S_T}$ 是 trip 开始时的交通状况。这样，最优的 latent route type $k$ 在 trip 一开始的时候就能拿到。从第二个轨迹观测值开始，这个 $k$ 就不需要再算了。</p>
<p>对于起点 $S_T$，交通状况 $Z_{S_T}$ 的隐藏状态可以通过下面公式计算：</p>
<script type="math/tex; mode=display">\tag{22}
f_1(Z_{S_T}) = \text{CNN} (Z_{S_T}),</script><p>然后 $z_{S_T}$ 可以从 $q_\phi (z_{S_T} \mid Z_{S_T})$ 里面采样得到：</p>
<script type="math/tex; mode=display">\tag{23}
q_\phi (z_{S_T} \mid Z_{S_T}) = \mathcal{N}(\mu_{Z_{S_T}}, diag(\sigma^2_{Z_{S_T}})),</script><p>然后，$\tau_{S_T}$ 可以通过 $f_2(\cdot)$ 得到：</p>
<script type="math/tex; mode=display">\tag{24}
\tau_{S_T} = f_2(S_T, z_{S_T}) = \text{NN}(S_T, z_{S_T}) = W S_T + Q z_{S_T},</script><p>同理，$\tau_{D_T}$ 按同样的方式计算。</p>
<p>然后 $q(k \mid S_T, D_T, z_{S_T})$ 通过 MLP 计算：</p>
<script type="math/tex; mode=display">\tag{25}
q(k \mid S_T, D_T, z_{S_T}) = \text{softmax}(f_t(\tau_{S_T}, \tau_{D_T})),</script><p>$f_5$ 就是 MLP。参数记为 $\delta = \{ f_5 (\cdot) \}$。</p>
<p>公式20里面，为了获得最优的 $k$，需要跑 $k$ 次。一个简单的方法是通过 $q_\gamma (k \mid T)$ 从轨迹 $T$ 里面找到最优的 $k$。因此 $q(k \mid S_T, D_T, z_{S_T})$ 和 $q_\gamma (k \mid T)$ 要尽可能的相近。我们用交叉熵最小化两个分布的差别：</p>
<script type="math/tex; mode=display">\tag{26}
l_k = - \sum^K_{k=1} q_\gamma (k \mid T) \log q(k \mid S_T, D_T, z_{S_T}),</script><p>这个交叉熵 $l_k$ 会和公式 16 的ELBO同时训练。然后在线检测阶段的时候，最优的 $k$ 是 $q(k \mid S_T, D_T, z_{S_T})$ 里面最高概率的那个。然后直接就能拿到最优 latent time-dependent route $u_k$。</p>
<p>需要注意的是，近似算法的训练过程和算法1不一样。首先，交通状况的使用不一样，近似算法只用了 $Z_{S_T}$。第二，公式26，是一个 co-training 过程，为了近似两个分布。训练后得到模型参数 $\phi, \gamma, \theta, \delta$。整个训练过程如算法3所示。先从 $Z_{S_T}$ 里面获得 $z_{S_T}$。然后获得最优的 latent time-dependent route $u_k$，这个数只要在轨迹开始的时候算一下就好了。然后基于 $p_\theta(\tau_{1:i} \mid u_k)$ 更新异常分数就好了。</p>
<h2 id="5-2-Complexity-Analysis"><a href="#5-2-Complexity-Analysis" class="headerlink" title="5.2 Complexity Analysis"></a>5.2 Complexity Analysis</h2><p>在线检测的复杂度 $\mathcal{O}(d_{h_t}(d_{h_t} + d_{\tau_i}))$。这项是新的轨迹观测值 $\tau_{i+1}$ 到来的时候 RNN 的变换过程的复杂度。因为 $d_{h_t}, d_{\tau_i}$ 是常数，所以近似算法的复杂度是 $\mathcal{O}(1)$</p>
</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/blog/tags/deep-learning/">deep learning</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/trajectory/">trajectory</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/blog/img/alipay.jpeg" alt="Alipay"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/blog/img/wechat.jpeg" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/2022/05/25/modeling-the-intensity-function-of-point-process-via-recurrent-neural-networks/"><span class="level-item">Modeling The Intensity Function Of Point Process Via Recurrent Neural Networks</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="/blog/img/avatar.png" alt="Davidham"></figure><p class="title is-size-4 is-block line-height-inherit">Davidham</p><p class="is-size-6 is-block">阿里菜鸟-时空数据挖掘-算法工程师</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hangzhou</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/blog/archives"><p class="title">89</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/blog/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/blog/tags"><p class="title">39</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/davidham3" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/davidham3"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="mail" href="mailto:mengxian.sc@alibaba-inc.com"><i class="fa fa-envelope"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/blog/categories/algorithms/"><span class="level-start"><span class="level-item">algorithms</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/dataset/"><span class="level-start"><span class="level-item">dataset</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B3%E5%8F%B0/"><span class="level-start"><span class="level-item">分布式平台</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">自然语言处理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文阅读笔记</span></span><span class="level-end"><span class="level-item tag">54</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E9%9A%8F%E7%AC%94/"><span class="level-start"><span class="level-item">随笔</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/blog/tags/attention/"><span class="tag">Attention</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/graph/"><span class="tag">Graph</span><span class="tag is-grey-lightest">27</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/hadoop/"><span class="tag">Hadoop</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/kafka/"><span class="tag">Kafka</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ner/"><span class="tag">NER</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/resnet/"><span class="tag">ResNet</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/sequence/"><span class="tag">Sequence</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/spark/"><span class="tag">Spark</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/spatial-temporal/"><span class="tag">Spatial-temporal</span><span class="tag is-grey-lightest">15</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/time-series/"><span class="tag">Time Series</span><span class="tag is-grey-lightest">12</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/algorithms/"><span class="tag">algorithms</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/computer-vision/"><span class="tag">computer vision</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/dataset/"><span class="tag">dataset</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag is-grey-lightest">52</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/event-sequence/"><span class="tag">event sequence</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/graph-convolutional-network/"><span class="tag">graph convolutional network</span><span class="tag is-grey-lightest">20</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/image-style-transfer/"><span class="tag">image style transfer</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/implicit-feedback/"><span class="tag">implicit feedback</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/language-modeling/"><span class="tag">language modeling</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/large-scale-learning/"><span class="tag">large-scale learning</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/learning-representations/"><span class="tag">learning representations</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag is-grey-lightest">19</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/machine-translation/"><span class="tag">machine translation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/multimodal/"><span class="tag">multimodal</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/natural-language-processing/"><span class="tag">natural language processing</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/normalization/"><span class="tag">normalization</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/point-process/"><span class="tag">point process</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/recommender-system/"><span class="tag">recommender system</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/seq2seq/"><span class="tag">seq2seq</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/software/"><span class="tag">software</span><span class="tag is-grey-lightest">16</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/softwares/"><span class="tag">softwares</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/super-resolution/"><span class="tag">super resolution</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/time-series/"><span class="tag">time series</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/trajectory/"><span class="tag">trajectory</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/virtual-machine/"><span class="tag">virtual machine</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/vscode/"><span class="tag">vscode</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E5%B7%B2%E5%A4%8D%E7%8E%B0/"><span class="tag">已复现</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E9%9A%8F%E7%AC%94/"><span class="tag">随笔</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2022-09-09T14:24:04.000Z">2022-09-09</time></p><p class="title is-6"><a class="link-muted" href="/blog/2022/09/09/deeptea-effective-and-efficient-online-time-dependent-trajectory-outlier-detection/">DeepTEA: Effective and Efficient Online Time-dependent Trajectory Outlier Detection</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2022-05-25T15:01:51.000Z">2022-05-25</time></p><p class="title is-6"><a class="link-muted" href="/blog/2022/05/25/modeling-the-intensity-function-of-point-process-via-recurrent-neural-networks/">Modeling The Intensity Function Of Point Process Via Recurrent Neural Networks</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2022-05-24T15:10:01.000Z">2022-05-24</time></p><p class="title is-6"><a class="link-muted" href="/blog/2022/05/24/multibench-multiscale-benchmarks-for-multimodal-representation-learning/">MULTIBENCH: Multiscale Benchmarks for Multimodal Representation Learning</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2022-05-23T15:27:10.000Z">2022-05-23</time></p><p class="title is-6"><a class="link-muted" href="/blog/2022/05/23/semi-supervised-learning-for-marked-temporal-point-processes/">Semi-supervised Learning for Marked Temporal Point Processes</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2022-05-20T15:35:04.000Z">2022-05-20</time></p><p class="title is-6"><a class="link-muted" href="/blog/2022/05/20/individual-mobility-prediction-via-attentive-marked-temporal-point-processes/">Individual Mobility Prediction via Attentive Marked Temporal Point Processes</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/blog/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/02/"><span class="level-start"><span class="level-item">February 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/01/"><span class="level-start"><span class="level-item">January 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/12/"><span class="level-start"><span class="level-item">December 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/11/"><span class="level-start"><span class="level-item">November 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/08/"><span class="level-start"><span class="level-item">August 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/07/"><span class="level-start"><span class="level-item">July 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/06/"><span class="level-start"><span class="level-item">June 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/05/"><span class="level-start"><span class="level-item">May 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/04/"><span class="level-start"><span class="level-item">April 2019</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/03/"><span class="level-start"><span class="level-item">March 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/02/"><span class="level-start"><span class="level-item">February 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/01/"><span class="level-start"><span class="level-item">January 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/12/"><span class="level-start"><span class="level-item">December 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/10/"><span class="level-start"><span class="level-item">October 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/09/"><span class="level-start"><span class="level-item">September 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/08/"><span class="level-start"><span class="level-item">August 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/06/"><span class="level-start"><span class="level-item">June 2018</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/05/"><span class="level-start"><span class="level-item">May 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/04/"><span class="level-start"><span class="level-item">April 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/03/"><span class="level-start"><span class="level-item">March 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/02/"><span class="level-start"><span class="level-item">February 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/01/"><span class="level-start"><span class="level-item">January 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2017/08/"><span class="level-start"><span class="level-item">August 2017</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/"><img src="/blog/img/logo.svg" alt="Davidham&#039;s blog" height="28"></a><p class="size-small"><span>&copy; 2022 Davidham</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://davidham3.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/blog/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>