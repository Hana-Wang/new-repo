<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>A Tutorial on Spectral Clustering - Davidham&#039;s blog</title><meta description="关于谱聚类的文章，主要包含了谱聚类和拉普拉斯矩阵的内容。最近研究 GCN 的原理的时候发现了这篇论文。Von Luxburg U. A tutorial on spectral clustering[J]. Statistics and Computing, 2007, 17(4): 395-416.原文链接：A Tutorial on Spectral Clustering"><meta property="og:type" content="blog"><meta property="og:title" content="A Tutorial on Spectral Clustering"><meta property="og:url" content="https://davidham3.github.io/2018/12/05/a-tutorial-on-spectral-clustering/"><meta property="og:site_name" content="Davidham&#039;s blog"><meta property="og:description" content="关于谱聚类的文章，主要包含了谱聚类和拉普拉斯矩阵的内容。最近研究 GCN 的原理的时候发现了这篇论文。Von Luxburg U. A tutorial on spectral clustering[J]. Statistics and Computing, 2007, 17(4): 395-416.原文链接：A Tutorial on Spectral Clustering"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://davidham3.github.io/blog/img/og_image.png"><meta property="article:published_time" content="2018-12-05T07:56:49.000Z"><meta property="article:modified_time" content="2022-04-25T14:58:30.500Z"><meta property="article:author" content="Davidham"><meta property="article:tag" content="machine learning"><meta property="article:tag" content="Graph"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/blog/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://davidham3.github.io/2018/12/05/a-tutorial-on-spectral-clustering/"},"headline":"Davidham's blog","image":["https://davidham3.github.io/blog/img/og_image.png"],"datePublished":"2018-12-05T07:56:49.000Z","dateModified":"2022-04-25T14:58:30.500Z","author":{"@type":"Person","name":"Davidham"},"description":"关于谱聚类的文章，主要包含了谱聚类和拉普拉斯矩阵的内容。最近研究 GCN 的原理的时候发现了这篇论文。Von Luxburg U. A tutorial on spectral clustering[J]. Statistics and Computing, 2007, 17(4): 395-416.原文链接：A Tutorial on Spectral Clustering"}</script><link rel="canonical" href="https://davidham3.github.io/2018/12/05/a-tutorial-on-spectral-clustering/"><link rel="icon" href="/blog/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/"><img src="/blog/img/logo.svg" alt="Davidham&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">Home</a><a class="navbar-item" href="/blog/archives">Archives</a><a class="navbar-item" href="/blog/categories">Categories</a><a class="navbar-item" href="/blog/tags">Tags</a><a class="navbar-item" href="/blog/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-12-05T07:56:49.000Z" title="2018-12-05T07:56:49.000Z">2018-12-05</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">20 minutes read (About 3034 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">A Tutorial on Spectral Clustering</h1><div class="content"><p>关于谱聚类的文章，主要包含了谱聚类和拉普拉斯矩阵的内容。最近研究 GCN 的原理的时候发现了这篇论文。<br>Von Luxburg U. A tutorial on spectral clustering[J]. Statistics and Computing, 2007, 17(4): 395-416.<br>原文链接：<a href="https://arxiv.org/abs/0711.0189">A Tutorial on Spectral Clustering</a><br><a id="more"></a></p>
<h1 id="2-Similarity-graphs"><a href="#2-Similarity-graphs" class="headerlink" title="2 Similarity graphs"></a>2 Similarity graphs</h1><p>给定一组数据点 $x_1, …, x_n$ 还有数据点 $x_i$ 和 $x_j$ 之间的相似性 $s_{ij} \geq 0$，聚类的目标是将样本点分到几个组中，组的样本相似，不同组的样本不相似。如果没有更多的信息，使用 <em>similarity graph</em> 表示数据是一个好的方法，$G = (V, E)$。每个顶点 $v_i$ 表示一个数据点 $x_i$。如果相似度 $s_{ij}$ 是正的，且大于一个确定的阈值，那么两个顶点相连，边的权重为 $s_{ij}$。聚类的问题可以使用相似度图重新定义为：我们想找到一个划分方案，使得不同组之间的边有很小的权重（意味着不同类簇间的样本不相似），同组内的权重较高（意味着同一类簇的样本相似）。我们首先引入一些符号和性质。</p>
<h2 id="2-1-Graph-notation"><a href="#2-1-Graph-notation" class="headerlink" title="2.1 Graph notation"></a>2.1 Graph notation</h2><p>$G = (V, E)$ 是无向图，顶点集 $V = \lbrace v_1, …, v_n \rbrace $。我们假设图 $G$ 是带权的，边有非负权重 $w_{ij} \geq 0$。带权的邻接矩阵是 $W = (w_{ij})_{i,j=1,…,n}$。如果 $w_{ij} = 0$，表示顶点 $v_i$ 和 $v_j$之间没有边。因为 $G$ 是无向的，所以 $w_{ij} = w_{ji}$。顶点 $v_i \in V$ 的度定义为：</p>
<script type="math/tex; mode=display">
d_i = \sum^n_{j = 1} w_{ij}.</script><p>事实上，这个加和只会在所有和 $v_i$ 邻接的顶点上做， 因为和其他的顶点之间的边权重为0。度矩阵 $D$ 定义为对角矩阵，对角线上是度 $d_1, …, d_n$。给定顶点的子集 $A \subset V$，它的补集 $V \ \backslash \ A$ 表示为 $\bar{A}$。定义一个指示向量 $1_A = (f_1, \dots f_n)’ \in \mathbb{R}^n$，如果 $v_i \in A$，$f_i = 1$，否则 $f_i = 0$。我们在做求和的时候，比如 $\sum_{i \in A} w_{ij}$， 把 $\lbrace i \mid v_i \in A \rbrace $ 简记为 $i \in A$。对于两个不相交的集合 $A, B \subset V$，定义：</p>
<script type="math/tex; mode=display">
W(A, B) := \sum_{i \in A, j \in B} w_{ij}.</script><p>我们考虑两个不同的方式来描述子集 $A \subset V$ 的“大小”：</p>
<script type="math/tex; mode=display">
\vert A \vert := A 的顶点数\\
\text{vol}(A) := \sum_{i \in A} d_i.</script><p>直观上来讲，$\vert A \vert$ 通过顶点数描述了 $A$ 的大小，但是 $\text{vol}(A)$ 通过对 $A$ 中所有的边进行加和得到。如果 $A$ 中的两个结点可以通过一条路径连接，而且中间的点都在 $A$ 中，那么称子集 $A \subset V$ 是连通的。如果子集是连通的，且顶点集 $A$ 和 $\bar{A}$ 之间没有结点相连，那么称 $A$ 是一个连通分量。如果 $A_i \cap A_j = \emptyset$ 且 $A_1 \cup \dots \cup A_k = V$，那么非空集合 $A_1, \dots, A_k$ 是图的一个划分。</p>
<h2 id="2-2-Different-similarity-graphs"><a href="#2-2-Different-similarity-graphs" class="headerlink" title="2.2 Different similarity graphs"></a>2.2 Different similarity graphs</h2><p>有一些流行的方法对顶点间的相似度或距离构建图。构建相似度图的目标是对样本之间的局部邻居关系建模。</p>
<p><strong>The $\varepsilon$-neighborhood graph:</strong> 我们把距离小于 $\varepsilon$ 的样本连起来。因为连接起来的样本点基本是一个尺度的，考虑边的权重不会增加更多的信息。所以，$\varepsilon$-邻居图通常是无权图。</p>
<p><strong>$k$-nearest neighbor graphs:</strong> 如果 $v_j$ 是 $v_i$ 的 $k$-近邻邻居，那目标是连接 $v_i$ 和 $v_j$。但是，这个定义会得到一个有向图，因为邻居间的关系是非对称的。有两种方法变成有向。第一种是忽略边的方向，也就是用无向边连接。结果通常称为 $k$-近邻邻居图。第二种方法是如果两个顶点互为对方的 $k$-近邻邻居，那么相连。得到的图称为 <em>mutual $k$-nearest neighbor graph</em>。这两种图的边都是顶点的相似度。</p>
<p><strong>The fully connected graph:</strong> 我们简单的连接有着正的相似度的顶点，边的权重就是相似度 $s_{ij}$。因为图应该表示局部邻居关系，这个构建方法只在相似度能体现局部邻居关系时才有效。举个相似度函数的例子，高斯相似度函数 $s(x_i, x_j) = \exp(- \Vert x_i - x_j \Vert ^ 2 / (2 \sigma^2))$，参数 $\sigma$ 控制了邻居的宽度。这个参数和 $\varepsilon$-邻居图中的 $\varepsilon$ 的角色差不多。</p>
<p>上面提到的图是谱聚类中常用的。据我们所知，相似度图如何影响谱聚类的结果还不为所知。不同的图的表现形式我们会在第八节讨论。</p>
<h1 id="3-Graph-Laplacians-and-their-basic-properties"><a href="#3-Graph-Laplacians-and-their-basic-properties" class="headerlink" title="3 Graph Laplacians and their basic properties"></a>3 Graph Laplacians and their basic properties</h1><p>谱聚类的主要工具是图拉普拉斯矩阵。有一个领域致力研究这些矩阵，称为谱图理论(e.g., see Chung, 1997)。我们这节定义不同的拉普拉斯矩阵，指出他们的重要性质。我们会仔细的对比不同的拉普拉斯矩阵。注意，事实上没有一个统一的说法说哪个矩阵就是 “graph Laplacian”。通常，每个作者都称他们使用的矩阵是拉普拉斯矩阵。因此，在读关于拉普拉斯矩阵的论文的时候需要注意。</p>
<p>假设 $G$ 是无向带权图，权重矩阵 $W$，$w_{ij} = w_{ji} \geq 0$。使用一个矩阵的特征向量时，我们没有必要假设他们是归一化的。举个例子，常向量 $1$ 和他的倍数 $a1$ 在 $a = \not 0$ 的时候被认为是相同的特征向量。特征值总时升序排列，而且会有多重性。前 $k$ 个特征值，我们指的是前 $k$ 个最小的特征值。</p>
<h2 id="3-1-The-unnormalized-graph-Laplacian"><a href="#3-1-The-unnormalized-graph-Laplacian" class="headerlink" title="3.1 The unnormalized graph Laplacian"></a>3.1 The unnormalized graph Laplacian</h2><p>非归一化的图拉普拉斯矩阵定义为：</p>
<script type="math/tex; mode=display">
L = D - W.</script><p>关于它的性质的论文在 Mohar(1991, 1997)。下面性质是谱聚类需要的性质：</p>
<p><strong>Proposition 1 (Properties of $L$)</strong> 拉普拉斯矩阵满足以下性质：</p>
<ol>
<li>对于每个向量 $f \in \mathbb{R}^n$，我们有：</li>
</ol>
<script type="math/tex; mode=display">
f'Lf = \frac{1}{2} \sum^n_{i,j=1} w_{ij}(f_i - f_j)^2.</script><ol>
<li>$L$ 是对称且半正定的。</li>
<li>$L$ 最小的特征值是 $0$，对应的特征向量是常向量 $1$。</li>
<li>$L$ 有 $n$ 个非负实数特征值 $0 = \lambda_1 \leq \lambda_2 \leq \dots \lambda_n$。</li>
</ol>
<p><em>Proof.</em><br>Part (1)：由 $d_i$ 的定义得：</p>
<script type="math/tex; mode=display">
\begin{aligned}
f'Lf &= f'Df - f'Wf = \sum^n_{i=1}d_i f^2_i - \sum^n_{i,j=1} f_i f_j w_{ij}\\
&=\frac{1}{2} \Bigg( \sum^n_{i=1} d_i f^2_i - 2 \sum^n_{i,j=1} f_i f_j w_{ij} + \sum^n_{j=1} d_j f^2_j \Bigg) = \frac{1}{2} \sum^n_{i,j=1} w_{ij} (f_i - f_j)^2.
\end{aligned}</script><p>Part (2)：$L$ 的对称性是因为 $W$ 和 $D$ 是对称的。半正定是 Part (1) 的结果，对于任意的 $f \in \mathbb{R}^n$，$f’Lf \geq 0$。</p>
<p>Part (3)：显而易见。</p>
<p>Part (4)：由(1) 和 (3) 推出。</p>
<p>注意：非归一化的拉普拉斯矩阵不依赖于邻接矩阵 $W$ 的对角线上的元素。邻接矩阵非对角线上的元素得到非归一化的拉普拉斯矩阵。图中的自连接不会改变对应的拉普拉斯矩阵。<br>（这里说白了就是，拉普拉斯矩阵非对角线位置上的元素是邻接矩阵对应位置的元素的相反数，如果顶点加自连接，那么度矩阵就会对应地增加，D-W在对角线上还是一样的数，不会变）</p>
<p>非归一化的拉普拉斯矩阵的特征值和特征向量可以用于描述图的很多性质，参见 Mohar(1991, 1997)。对于谱聚类来说一个重要的性质是：</p>
<p><strong>Proposition 2 (Number of connected components and the spectrum of $L$)</strong> 图 $G$ 是无向非负权重的图。拉普拉斯矩阵的特征值 $0$ 的多重性 $k$ 等于图中的连通分量 $A_1, \dots, A_k$ 的数量。特征值 $0$ 的特征空间通过指示向量 $1_{A_1}, \dots, 1_{A_k}$ 生成。</p>
<p><em>Proof.</em> 我们先以 $k = 1$ 为例，也就是说只有一个连通图。假设 $f$ 是特征值 $0$ 对应的特征向量。我们知道：</p>
<script type="math/tex; mode=display">
0 = f'Lf = \sum^n_{i,j=1} w_{ij} (f_i - f_j)^2.</script><p>因为权重 $w_{ij}$ 是非负的，如果所有的项 $w_{ij} (f_i - f_j)^2$ 都消失了，这个和就会很小。因此，如果两个顶点相连（权重大于0），那么 $f_i$ 需要等于 $f_j$。我们可以发现，对于所有顶点 $f$ 需要是一个相同的常数，且这些点可以通过一条路径相连。此外，因为无向图内连通分量所有的顶点可以通过一条路径相连，$f$ 对于整个连通分量来说需要是一个常数。在只有一个连通分量的图中，我们因此只有一个常向量 $1$ 作为特征向量，对应的特征值为 $0$，显然这个向量就是这个连通分量的指示向量。</p>
<p>现在考虑 $k$ 个连通分量。为了不失一般性，我们假设顶点是根据连通分量排序的。这样，邻接矩阵 $W$ 有一个块对角形式，对于矩阵 $L$ 也是如此：</p>
<script type="math/tex; mode=display">
L = \begin{pmatrix}
   L_1 & & & \\
   & L_2 & & \\
   & & \ddots & \\
   & & & L_k
\end{pmatrix}</script><p>注意：块 $L_i$ 是一个关于它自己的拉普拉斯矩阵，也就是对应第 $i$ 个子图的拉普拉斯矩阵。在这个对角都是块矩阵的例子中，我们知道 $L$ 的谱是所有的 $L_i$ 的谱的并集，对应的 $L$ 的特征向量是 $L_i$ 的特征向量，其他方块的位置都是0.因为每个 $L_i$ 是一个连通图的拉普拉斯矩阵，我们知道每个 $L_i$ 在第 $i$ 个连通分量上，有特征值 $0$，且多重性为 $1$，对应的特征向量常向量。因此，矩阵 $L$ 的特征值 $0$ 的个数就等于连通分量数，而且对应的特征向量是连通分量的指示向量。</p>
<h2 id="3-2-The-normalized-graph-Laplacians"><a href="#3-2-The-normalized-graph-Laplacians" class="headerlink" title="3.2 The normalized graph Laplacians"></a>3.2 The normalized graph Laplacians</h2><p>在文献中有两个归一化的拉普拉斯矩阵。两个矩阵紧密相连，定义如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
& L_{sym} := D^{-1/2} L D^{-1/2} = I - D^{-1/2} W D^{-1/2}\\
& L_{rw} := D^{-1} L = I - D^{-1} W.
\end{aligned}</script><p>我们将第一个矩阵表示为 $L_{sym}$，因为它是一个对称阵，第二个矩阵表示为 $L_{rw}$，因为它和随机游走有关。接下来我们总结一下这两个矩阵的性质。关于归一化的拉普拉斯矩阵的引用在 Chung (1997)。</p>
<p><strong>Proposition 3 (Properties of $L_{sym}$ and $L_{rw}$)</strong> 归一化的拉普拉斯矩阵满足以下性质：</p>
<ol>
<li>对于每个 $f \in \mathbb{R}^n$，我们有：</li>
</ol>
<script type="math/tex; mode=display">
f' L_{sym} f = \frac{1}{2} \sum^n_{i,j=1} w_{ij} \Bigg( \frac{f_i}{\sqrt{d_i}} - \frac{f_j}{\sqrt{d_j}} \Bigg)^2.</script><ol>
<li>$\lambda$ 是 $L_{rw}$ 的一个特征值，对应的特征向量 $u$，当且仅当 $\lambda$ 是 $L_{sym}$ 的一个特征值且对应的特征向量 $w = D^{1/2}u$。</li>
<li>$\lambda$ 是 $L_{rw}$ 的一个特征值，对应的特征向量 $u$，当且仅当 $\lambda$ 和 $u$ 是 generalized eigenproblem $Lu = \lambda Du$ 的解。</li>
<li>$0$ 是 $L_{rw}$ 的特征值，常向量 $1$ 是特征向量。$0$ 是 $L_{sym}$ 的特征值且特征向量是 $D^{1/2}1$。</li>
<li>$L_{sym}$ 和 $L_{rw}$ 是半正定的，有 $n$ 个非负的实数特征值 $0 = \lambda_1 \leq \dots \leq \lambda_n$。</li>
</ol>
</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/blog/tags/machine-learning/">machine learning</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/graph/">Graph</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/blog/img/alipay.jpeg" alt="Alipay"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/blog/img/wechat.jpeg" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blog/2018/12/18/geometric-deep-learning-on-graphs-and-manifolds-using-mixture-model-cnns/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Geometric deep learning on graphs and manifolds using mixture model CNNs</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/2018/12/03/layer-normalization/"><span class="level-item">Layer Normalization</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="/blog/img/avatar.png" alt="Davidham"></figure><p class="title is-size-4 is-block line-height-inherit">Davidham</p><p class="is-size-6 is-block">...</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hangzhou</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/blog/archives"><p class="title">79</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/blog/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/blog/tags"><p class="title">33</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/davidham3"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="mail" href="mailto:chaosong@bjtu.edu.cn"><i class="fa fa-envelope"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/blog/categories/algorithms/"><span class="level-start"><span class="level-item">algorithms</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/dataset/"><span class="level-start"><span class="level-item">dataset</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B3%E5%8F%B0/"><span class="level-start"><span class="level-item">分布式平台</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">自然语言处理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文阅读笔记</span></span><span class="level-end"><span class="level-item tag">44</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E9%9A%8F%E7%AC%94/"><span class="level-start"><span class="level-item">随笔</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/blog/tags/attention/"><span class="tag">Attention</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/graph/"><span class="tag">Graph</span><span class="tag is-grey-lightest">27</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/hadoop/"><span class="tag">Hadoop</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/kafka/"><span class="tag">Kafka</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ner/"><span class="tag">NER</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/resnet/"><span class="tag">ResNet</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/sequence/"><span class="tag">Sequence</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/spark/"><span class="tag">Spark</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/spatial-temporal/"><span class="tag">Spatial-temporal</span><span class="tag is-grey-lightest">15</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/time-series/"><span class="tag">Time Series</span><span class="tag is-grey-lightest">12</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/algorithms/"><span class="tag">algorithms</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/computer-vision/"><span class="tag">computer vision</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/dataset/"><span class="tag">dataset</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag is-grey-lightest">42</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/graph-convolutional-network/"><span class="tag">graph convolutional network</span><span class="tag is-grey-lightest">20</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/image-style-transfer/"><span class="tag">image style transfer</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/implicit-feedback/"><span class="tag">implicit feedback</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/language-modeling/"><span class="tag">language modeling</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/large-scale-learning/"><span class="tag">large-scale learning</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag is-grey-lightest">19</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/machine-translation/"><span class="tag">machine translation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/natural-language-processing/"><span class="tag">natural language processing</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/normalization/"><span class="tag">normalization</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/recommender-system/"><span class="tag">recommender system</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/seq2seq/"><span class="tag">seq2seq</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/software/"><span class="tag">software</span><span class="tag is-grey-lightest">16</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/softwares/"><span class="tag">softwares</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/super-resolution/"><span class="tag">super resolution</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/virtual-machine/"><span class="tag">virtual machine</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/vscode/"><span class="tag">vscode</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E5%B7%B2%E5%A4%8D%E7%8E%B0/"><span class="tag">已复现</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E9%9A%8F%E7%AC%94/"><span class="tag">随笔</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-05-14T04:00:28.000Z">2020-05-14</time></p><p class="title is-6"><a class="link-muted" href="/blog/2020/05/14/%E5%8D%9A%E5%AE%A2%E9%87%8D%E8%A3%85/">博客重装...</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/software/">software</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-05-13T09:07:14.000Z">2020-05-13</time></p><p class="title is-6"><a class="link-muted" href="/blog/2020/05/13/neural-collaborative-filtering/">Neural Collaborative Filtering</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-02-12T16:12:07.000Z">2020-02-13</time></p><p class="title is-6"><a class="link-muted" href="/blog/2020/02/13/%E8%AE%B0%E4%B8%80%E6%AC%A1pyspark%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%EF%BC%8Cnp-frombuffer%E7%9A%84%E4%BD%BF%E7%94%A8/">记一次pyspark性能提升，np.frombuffer的使用</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B3%E5%8F%B0/">分布式平台</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-01-03T12:18:29.000Z">2020-01-03</time></p><p class="title is-6"><a class="link-muted" href="/blog/2020/01/03/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/">Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-01-02T09:03:30.000Z">2020-01-02</time></p><p class="title is-6"><a class="link-muted" href="/blog/2020/01/02/gman-a-graph-multi-attention-network-for-traffic-prediction/">GMAN: A Graph Multi-Attention Network for Traffic Prediction</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/02/"><span class="level-start"><span class="level-item">February 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/01/"><span class="level-start"><span class="level-item">January 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/12/"><span class="level-start"><span class="level-item">December 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/11/"><span class="level-start"><span class="level-item">November 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/08/"><span class="level-start"><span class="level-item">August 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/07/"><span class="level-start"><span class="level-item">July 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/06/"><span class="level-start"><span class="level-item">June 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/05/"><span class="level-start"><span class="level-item">May 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/04/"><span class="level-start"><span class="level-item">April 2019</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/03/"><span class="level-start"><span class="level-item">March 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/02/"><span class="level-start"><span class="level-item">February 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/01/"><span class="level-start"><span class="level-item">January 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/12/"><span class="level-start"><span class="level-item">December 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/10/"><span class="level-start"><span class="level-item">October 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/09/"><span class="level-start"><span class="level-item">September 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/08/"><span class="level-start"><span class="level-item">August 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/06/"><span class="level-start"><span class="level-item">June 2018</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/05/"><span class="level-start"><span class="level-item">May 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/04/"><span class="level-start"><span class="level-item">April 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/03/"><span class="level-start"><span class="level-item">March 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/02/"><span class="level-start"><span class="level-item">February 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/01/"><span class="level-start"><span class="level-item">January 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2017/08/"><span class="level-start"><span class="level-item">August 2017</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/"><img src="/blog/img/logo.svg" alt="Davidham&#039;s blog" height="28"></a><p class="size-small"><span>&copy; 2022 Davidham</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://davidham3.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/blog/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>