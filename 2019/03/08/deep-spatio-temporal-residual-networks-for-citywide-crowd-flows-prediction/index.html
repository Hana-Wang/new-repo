<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction - Davidham&#039;s blog</title><meta description="AAAI 2017, ST-ResNet，网格流量预测，用三个相同结构的残差卷积神经网络对近邻时间、周期、趋势（远期）分别建模。与 RNN 相比，RNN 无法处理序列长度过大的序列。三组件的输出结果进行集成，然后和外部因素集成，得到预测结果。原文地址：Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction"><meta property="og:type" content="blog"><meta property="og:title" content="Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction"><meta property="og:url" content="https://davidham3.github.io/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/"><meta property="og:site_name" content="Davidham&#039;s blog"><meta property="og:description" content="AAAI 2017, ST-ResNet，网格流量预测，用三个相同结构的残差卷积神经网络对近邻时间、周期、趋势（远期）分别建模。与 RNN 相比，RNN 无法处理序列长度过大的序列。三组件的输出结果进行集成，然后和外部因素集成，得到预测结果。原文地址：Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://davidham3.github.io/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig1.JPG"><meta property="og:image" content="https://davidham3.github.io/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig2.JPG"><meta property="og:image" content="https://davidham3.github.io/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig3.JPG"><meta property="og:image" content="https://davidham3.github.io/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig4.JPG"><meta property="og:image" content="https://davidham3.github.io/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig5.JPG"><meta property="og:image" content="https://davidham3.github.io/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig6.JPG"><meta property="og:image" content="https://davidham3.github.io/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Alg1.JPG"><meta property="og:image" content="https://davidham3.github.io/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table1.JPG"><meta property="og:image" content="https://davidham3.github.io/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table2.JPG"><meta property="og:image" content="https://davidham3.github.io/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table3.JPG"><meta property="article:published_time" content="2019-03-08T02:26:16.000Z"><meta property="article:modified_time" content="2022-04-25T14:58:30.547Z"><meta property="article:author" content="Davidham"><meta property="article:tag" content="Graph"><meta property="article:tag" content="deep learning"><meta property="article:tag" content="Spatial-temporal"><meta property="article:tag" content="graph convolutional network"><meta property="article:tag" content="Time Series"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig1.JPG"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://davidham3.github.io/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/"},"headline":"Davidham's blog","image":[],"datePublished":"2019-03-08T02:26:16.000Z","dateModified":"2022-04-25T14:58:30.547Z","author":{"@type":"Person","name":"Davidham"},"description":"AAAI 2017, ST-ResNet，网格流量预测，用三个相同结构的残差卷积神经网络对近邻时间、周期、趋势（远期）分别建模。与 RNN 相比，RNN 无法处理序列长度过大的序列。三组件的输出结果进行集成，然后和外部因素集成，得到预测结果。原文地址：Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction"}</script><link rel="canonical" href="https://davidham3.github.io/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/"><link rel="icon" href="/blog/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/"><img src="/blog/img/logo.svg" alt="Davidham&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">Home</a><a class="navbar-item" href="/blog/archives">Archives</a><a class="navbar-item" href="/blog/categories">Categories</a><a class="navbar-item" href="/blog/tags">Tags</a><a class="navbar-item" href="/blog/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2019-03-08T02:26:16.000Z" title="2019-03-08T02:26:16.000Z">2019-03-08</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">28 minutes read (About 4217 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction</h1><div class="content"><p>AAAI 2017, ST-ResNet，网格流量预测，用三个相同结构的残差卷积神经网络对近邻时间、周期、趋势（远期）分别建模。与 RNN 相比，RNN 无法处理序列长度过大的序列。三组件的输出结果进行集成，然后和外部因素集成，得到预测结果。原文地址：<a href="https://arxiv.org/abs/1610.00081">Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction</a><br><a id="more"></a></p>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>对于交通管理和公共安全来说，预测人流很重要，但这个问题也很有挑战性，因为收到很多复杂的因素影响，如区域内的交通、事件、天气。我们提出了一个基于深度学习的模型 ST-ResNet，对城市内的每个区域的人流的进出一起预测。我们基于时空数据独一的属性，设计了一个端到端的结构。我们使用残差神经网络框架对时间近邻、周期、趋势属性建模。对每个属性，我们设计了残差卷积的一个分支，每个分支对人流的空间属性建模。ST-ResNet 基于数据动态地聚合三个残差神经网络的输出，给不同的分支和区域分配权重。聚合结果还融合了外部因素，像天气或日期。实验在北京和纽约两个数据集上开展。</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>对于交通管理和公共安全来说，预测人流很重要（Zheng et al. 2014）。举个例子，2015年新年夜，上海有大量人群涌入一个区域，导致 36 人死亡。2016年六月中旬，数百名 Pokemon Go 玩家冲入纽约中央公园，为了抓一只特别稀有的怪，导致严重的踩踏事故。如果可以预测一个区域的人流，这样的悲剧可以通过应急措施避免，像提前做交通管控，发布预警，疏散人群等。</p>
<p>我们在这篇文章中预测两类人流（Zhang et al. 2016)：如图 1（a）所示，流入和流出。流入是在给定时间段，从其他区域进入到一个区域的交通运载量。流出表示给定时段内，从一个区域向其他区域的交通运载量。两个流量都是区域间的人口流动。了解这个对风险评估和交通管理有很大帮助。流入/流出可以通过行人数量、邻近道路车辆数、公共运输系统的人数、或是所有的都加起来。图 1（b）展示了一个例子。我们可以使用手机信号测量行人数，$r_2$ 的流入和流出分别为 3 和 1。类似地，使用车辆 GPS 轨迹，分别是 0 和 3。</p>
<center><img src="/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig1.JPG" class title="Figure1"></center>

<p>然而，同时预测城市每个区域人口的流入和流出是很有难度的，有 3 个复杂的因素：</p>
<ol>
<li>空间依赖。区域 $r_2$ 的流入（图1（a））受邻近区域（像 $r_1$）和遥远区域流出的影响。$r_2$ 的流出也受其他区域（$r_3$）流入的影响。$r_2$ 的流入也影响其自身。</li>
<li>时间依赖。一个区域的人流受到近期和远期时间影响。举个例子，早上8点发生的交通拥堵可能会影响到 9 点。此外，早高峰的交通状况可能在接连的几天都是相似的，每 24 小时一次。而且随着冬天的到来，早高峰时间可能越来越晚。温度下降，日初变晚会使人们起床时间变晚。</li>
<li>外部影响。一些像天气和事件的外部因素可能会显著地改变城市内不同区域的人口流动。</li>
</ol>
<p>为了解决这些问题，我们提出了一个深度深空残差网络 (ST-ResNet) 对每个区域的流入和流出同时预测。我们的贡献有 4 点：</p>
<ul>
<li>ST-ResNet 使用基于卷积的残差神经网络对城市内两个邻近的和遥远的区域的空间依赖建模，同时还确信了模型的预测精度不会因为模型的深度增加而降低。</li>
<li>我们将人口流动的时间属性分为三种，时间近邻、周期、趋势。ST-ResNet 使用三个残差网络对这些属性建模。</li>
<li>ST-ResNet 动态地聚合三个上述网络的输出，给不同的分支和区域分配权重。聚合还融合了外部因素。</li>
<li>我们使用北京出租车的轨迹数据和气象数据，纽约自行车轨迹数据。结果表示我们的方法比 6 个 baseline 都好。</li>
</ul>
<h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><p>简要回顾人流预测问题（Zhang el al. 2016; Hoang, Zheng, and Singh 2016），介绍残差学习（He et al. 2016）。</p>
<h2 id="Formulation-of-Crowd-Flows-Problem"><a href="#Formulation-of-Crowd-Flows-Problem" class="headerlink" title="Formulation of Crowd Flows Problem"></a>Formulation of Crowd Flows Problem</h2><p><strong>Definition 1(Region (Zhang et al. 2016))</strong> 根据不同粒度级和语义，一个地点的定义有很多。我们根据经纬度将城市划分成 $I \times J$ 个网格，一个网格表示一个区域，如图 2(a)。</p>
<center><img src="/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig2.JPG" class title="Figure2"></center>

<p>**Definition 2(Inflow/outflow (Zhang et al. 2016)) $\mathbb{P}$ 是第 t 时段的轨迹集合。对于第 $i$ 行第 $j$ 列的网格，时段 $t$ 流入和流出的人流分别定义为：</p>
<script type="math/tex; mode=display">
x^{in,i,j}_t = \sum_{T_r \in \mathbb{P}} \vert \lbrace k > 1 \mid g_{k-1} \not \in (i, j) \wedge g_k \in (i,j) \rbrace \vert
\\
x^{out,i,j}_t = \sum_{T_r \in \mathbb{P}} \vert \lbrace k \geq 1 \mid g_k \in (i,j) \wedge g_{k+1} \not \in (i,j) \rbrace \vert</script><p>其中 $T_r: g_1 \rightarrow g_2 \rightarrow \cdots \rightarrow g_{\vert T_r \vert}$ 是 $\mathbb{P}$ 中的轨迹，$g_k$ 是地理坐标；$g_k \in (i,j)$ 表示点 $g_k$ 落在 $(i, j)$ 内；$\vert · \vert$ 表示集合基数。</p>
<p>时段 $t$ ，所有区域的流入和流出可以表示成 $\mathbf{X}_t \in \mathbb{R}^{2 \times I \times J}$，$(\mathbf{X}_t)_{0,i,j}=x^{in,i,j}_t, (\mathbf{X}_t)_{1,i,j} = x^{out,i,j}_t$。流入矩阵如图2(b)。</p>
<p>空间区域可以表达成一个 $I \times J$ 的区域，有两类流动，所以观测值可以表示为 $\mathbf{X} \in \mathbb{R}^{2 \times I \times J}$。</p>
<p><strong>Problem 1</strong> 给定历史观测值 $\lbrace \mathbf{X}_t \mid t = 0,\dots,n-1 \rbrace$，预测 $\mathbf{X}_n$。</p>
<h2 id="Deep-Residual-Learning"><a href="#Deep-Residual-Learning" class="headerlink" title="Deep Residual Learning"></a>Deep Residual Learning</h2><script type="math/tex; mode=display">\tag{1}
\mathbf{X}^{(l+1)} = \mathbf{X}^{(l)} + \mathcal{F}(\mathbf{X}^{(l)})</script><h1 id="Deep-Spatio-Temporal-Residual-Networks"><a href="#Deep-Spatio-Temporal-Residual-Networks" class="headerlink" title="Deep Spatio-Temporal Residual Networks"></a>Deep Spatio-Temporal Residual Networks</h1><center><img src="/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig3.JPG" class title="Figure3"></center>

<p>图 3 展示了 ST-ResNet的架构，4 个部分分别对时间近邻、周期、远期、外部因素建模。如图 3 所示，首先将流入和流出作为两个通道放到矩阵中，使用定义 1 和 2 引入的方法。我们将时间轴分为三个部分，表示近期时间、邻近历史、远期历史。三个时段的两通道的流动矩阵分别输入上述模型，对三种时间属性建模。这三个组件结构相同，都是残差网络。这样的结构捕获邻近和遥远区域间的空间依赖。外部组件中，我们手动的从数据集中提取了特征，如天气、事件等，放入两层全连接神经网络中。前三个组件的输出基于参数矩阵融合为 $\mathbf{X}_{Res}$，参数矩阵给不同的区域不同的组件分配权重。$\mathbf{X}_{Res}$ 然后与外部组件 $\mathbf{X}_{Ext}$ 集成。最后，聚合结果通过 Tanh 映射到 $[-1, 1]$，在反向传播会比 logistic function 收敛的更快 (LeCun et al. 2012)。</p>
<h2 id="Structures-of-the-First-Three-Components"><a href="#Structures-of-the-First-Three-Components" class="headerlink" title="Structures of the First Three Components"></a>Structures of the First Three Components</h2><p>如图 4。</p>
<center><img src="/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig4.JPG" class title="Figure4"></center>

<p><strong><em>Convolution</em></strong> 一个城市通常很大，包含很多距离不同的区域。直观上来说，邻近区域的人流会影响其他区域，可以通过 CNN 有效地处理，CNN 也被证明在层级地捕获空间信息方面很强 (LeCun et al. 1998)。而且，如果两个遥远地方通过地铁或高速公路连接，那么这两个区域间就有依赖关系。为了捕获任何区域的空间依赖，我们需要设计一个很多层的 CNN 模型，因为一个卷积层只考虑空间近邻，受限于它卷积核的大小。同样的问题在视频序列生成任务中也有，当输入和输出有同样的分辨率的时候(Mathieu, Couprie, and LeCun 2015)。为了避免下采样导致的分辨率损失引入了几种方法，同时还保持遥远的依赖关系(Long, Shelhamer, and Darrell 2015)。与传统的 CNN 不同的是，我们没有使用下采样，而是只使用卷积 (Jain et al. 2007)。如图 4(a)，图中有 3 个多级的 feature map，通过一些卷积操作相连。一个高层次的结点依赖于 9 个中间层次的结点，这些又依赖于低层次的所有结点。这意味着一个卷积可以很自然地捕获空间近邻依赖，堆叠卷积可以更多地捕获遥远的空间依赖。</p>
<p>图 3 的近邻组件使用了一些 2 通道流动矩阵对近邻时间依赖建模。令最近的部分为 $[\mathbf{X}_{t-l_c}, \mathbf{X}_{t-(l_c-1)}, \dots, \mathbf{X}_{t-1}]$，也称为近邻依赖序列。我们将他们沿第一个轴（时间）拼接，得到一个张量 $\mathbf{X}^{(0)}_c \in \mathbb{R}^{2l_c \times I \times J}$，然后使用卷积（图 3 中的 Conv1）：</p>
<script type="math/tex; mode=display">\tag{2}
\mathbf{X}^{(1)}_c = f(W^{(1)}_c \ast \mathbf{X}^{(0)}_c + b^{(1)}_c)</script><p>其中 $\ast$ 表示卷积；$f$ 是激活函数；$W^{(1)}_c, b^{(1)}_c$ 是参数。</p>
<p><strong><em>Residual Unit.</em></strong> 尽管有 ReLU 职业那个的激活函数和正则化技巧，深度卷积网络在训练上还是很难。但我们仍然需要深度神经网络捕获非常大范围的依赖。对于典型的流量数据，假设输入大小是 $32 \times 32$，卷积核大小是 $3 \times 3$，如果我们想对城市范围的依赖建模，至少需要连续 15 个卷积层。为了解决这个问题，我们使用残差学习(He et al. 2015)，在训练超过 1000 层的网络时很有效。</p>
<p>在我们的 ST-ResNet(如图 3)，我们在 Conv1 上堆叠 $L$ 个残差单元如下：</p>
<script type="math/tex; mode=display">\tag{3}
\mathbf{X}^{(l+1)}_c = \mathbf{X}^{(l)}_c + \mathcal{F}(\mathbf{X}^{(l)}_c; \theta^{(l)}_c), l = 1, \dots, L</script><p>$\mathcal{F}$ 是残差函数，即 ReLU + Convolution，如图 4(b)。我们还在 ReLU 之前加了 <em>Batch Normalization</em>。在第 $L$ 个残差单元前，我们使用了一个卷积层，图 3 中的 Conv2。2 个卷积和 $L$ 个残差单元，图 3 中的近邻组件的输出是 $\mathbf{X}^{(l+2)}_c$。</p>
<p>同样的，使用上面的操作，我们可以构建 <em>周期</em> 和 <em>趋势</em> 组件，如图 3。假设时段 $p$ 有 $l_p$ 个时间间隔。那么 <em>时段</em> 依赖序列是 $[\mathbf{X}_{t-l_p \cdot p}, \mathbf{X}_{t-(l_p - 1) \cdot p}, \dots, \mathbf{X}_{t-p}]$。使用式 2 和 式 3 那样的卷积和 $L$ 个残差单元，<em>周期</em> 组件的输出是 $\mathbf{X}^{(L + 2)}_p$。同时，<em>趋势</em> 组件的输出是 $\mathbf{X}^{(L+2)}_q$，输入是 $[\mathbf{X}_{t-l_q \cdot q}, \mathbf{X}_{t-(l_q - 1) \cdot q}, \dots, \mathbf{X}_{t-q}]$，$l_q$ 是<em>趋势</em>依赖序列的长度，$q$ 是趋势跨度。需要注意的是 $p$ 和 $q$ 是两个不同类型的周期。在实际的实现中，$p$ 等于一天，描述的是日周期，$q$ 是一周，表示周级别的趋势。</p>
<h2 id="The-Structure-of-the-External-Component"><a href="#The-Structure-of-the-External-Component" class="headerlink" title="The Structure of the External Component"></a>The Structure of the External Component</h2><p>交通流会被很多复杂的外部因素所影响，如天气或事件。图 5(a) 表示假期（春节）时的人流和平时的人流很不一样。图 5(b) 表示相比上周的同一天，突然而来的大雨会减少此时办公区域的人流。令 $E_t$ 为特征向量，表示预测的时段 $t$ 的外部因素。我们的实现中，我们主要考虑天气、假期事件、元数据（工作日、周末）。详细情况见表 1。为了预测时段 $t$ 的交通流，假期事件和元数据可以直接获得。然而，未来时段 $t$ 的天气预报不知道。可以使用时段 $t$ 的天气预报，或是 $t-1$ 时段的天气来近似。我们在 $E_t$ 上堆叠两个全连接层，第一层可以看作是每个子因素的嵌入层。第二层用来从低维映射到和 $\mathbf{X}_t$ 一样的高维上。图 3 中外部组件的输出表示为 $\mathbf{X}_{Ext}$，参数是$\theta_{Ext}$。</p>
<center><img src="/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig5.JPG" class title="Figure5"></center>

<h2 id="Fusion"><a href="#Fusion" class="headerlink" title="Fusion"></a>Fusion</h2><p>我们先用一个参数矩阵融合前三个组件，然后融合外部组件。</p>
<p>图6(a)和(d)展示了表1展示的北京轨迹数据的比例曲线，x轴是两个时段的时间差，y轴是任意两个有相同时间差的流入的平均比例。两个不同区域的曲线在时间序列上表现出了时间联系，也就是近期的流入比远期的流入更相关，表现出了事件近邻性。两条曲线有两个不同的形状，表现出不同区域可能有不同性质的近邻性。图6(b)和(e)描绘了7天所有时段的流入。我们可以观察到两个区域明显的日周期性。在办公区域，工作日的峰值比周末的高很多。住宅区在工作日和周末有相似的峰值。图6(c)和(f)描述了2015年3月到2015年6月一个特定时段(9:00pm-9:30pm)的流入。随着时间的推移，办公区域的流入逐渐减少，住宅区逐渐增加。不同的区域表现出了不同的趋势。总的来说，两个区域的流入受到近邻、周期、趋势三部分影响，但是影响程度是不同的。我们也发现其他区域也有同样的性质。</p>
<center><img src="/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig6.JPG" class title="Figure6"></center>

<p>综上，不同区域受近邻、周期、趋势的影响，但是影响程度不同。受这些观察的启发，我们提出了一个基于矩阵参数的融合方法。</p>
<p><strong><em>Parametric-matrix-based fusion.</em></strong> 我们融合图 3 中前三个组件：</p>
<script type="math/tex; mode=display">\tag{4}
\mathbf{X}_{Res} = \mathbf{W}_c \odot \mathbf{X}^{(L+2)}_c + \mathbf{W}_p \odot \mathbf{X}^{(L+2)}_p + \mathbf{W}_q \odot \mathbf{X}^{(L+2)}_q</script><p>$\odot$ 是哈达玛乘积，$\mathbf{W}$ 是参数，分别调整三个组件的影响程度。</p>
<p><strong><em>Fusing the external component.</em></strong> 我们直接地将前三个组件的输出和外部组件融合，如图3。最后，时段 $t$ 的预测值，表示为 $\hat{\mathbf{X}}_t$ 定义为：</p>
<script type="math/tex; mode=display">\tag{5}
\hat{\mathbf{X}}_t = \mathrm{tanh}(\mathbf{X}_{Res} + \mathbf{X}_{Ext})</script><p>我们的 ST-ResNet 可以从三个流动与朕和外部因素特征通过最下滑 MSE 来训练：</p>
<script type="math/tex; mode=display">\tag{6}
\mathcal{L}(\theta) = \Vert \mathbf{X}_t - \hat{\mathbf{X}}_t \Vert^2_2</script><h2 id="Algorithm-and-Optimization"><a href="#Algorithm-and-Optimization" class="headerlink" title="Algorithm and Optimization"></a>Algorithm and Optimization</h2><p>算法1描述了 ST-ResNet 的训练过程。首先从原始序列构造训练实例。然后通过反向传播，用 Adam 算法训练。</p>
<center><img src="/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Alg1.JPG" class title="Algorithm1"></center>

<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Settings"><a href="#Settings" class="headerlink" title="Settings"></a>Settings</h2><p><strong>Datasets.</strong> 我们使用表 1 中展示的两个数据集。每个数据集都包含两个子集，轨迹和天气。</p>
<ul>
<li>TaxiBJ: 轨迹数据是出租车 GPS 数据和北京的气象数据，2013年7月1日到10月30日，2014年5月1日到6月30日，2015年5月1日到6月30日，2015年11月1日到2016年4月1日。使用定义2，我们获得两类人流。我们选择最后四周作为测试集，之前的都为训练集。</li>
<li>BikeNYC: 轨迹数据是2014年NYC Bike系统中取的，从4月1日到9月30日。旅行数据包含：持续时间、起点终点站点ID，起始终止时间。在数据中，最后10天选做测试集，其他选做训练集。</li>
</ul>
<center><img src="/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table1.JPG" class title="Table1"></center>

<p><strong>Baselines.</strong> 我们对比了6个baselines：HA, ARIMA, SARIMA, VAR, ST-ANN, DeepST.</p>
<center><img src="/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table2.JPG" class title="Table2"></center>

<center><img src="/blog/2019/03/08/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table3.JPG" class title="Table3"></center></div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/blog/tags/graph/">Graph</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/deep-learning/">deep learning</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/spatial-temporal/">Spatial-temporal</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/graph-convolutional-network/">graph convolutional network</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/time-series/">Time Series</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/blog/img/alipay.jpeg" alt="Alipay"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/blog/img/wechat.jpeg" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blog/2019/03/21/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/2019/03/07/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/"><span class="level-item">T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="/blog/img/avatar.png" alt="Davidham"></figure><p class="title is-size-4 is-block line-height-inherit">Davidham</p><p class="is-size-6 is-block">...</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hangzhou</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/blog/archives"><p class="title">79</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/blog/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/blog/tags"><p class="title">33</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/davidham3"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="mail" href="mailto:chaosong@bjtu.edu.cn"><i class="fa fa-envelope"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/blog/categories/algorithms/"><span class="level-start"><span class="level-item">algorithms</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/dataset/"><span class="level-start"><span class="level-item">dataset</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B3%E5%8F%B0/"><span class="level-start"><span class="level-item">分布式平台</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">自然语言处理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文阅读笔记</span></span><span class="level-end"><span class="level-item tag">44</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E9%9A%8F%E7%AC%94/"><span class="level-start"><span class="level-item">随笔</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/blog/tags/attention/"><span class="tag">Attention</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/graph/"><span class="tag">Graph</span><span class="tag is-grey-lightest">27</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/hadoop/"><span class="tag">Hadoop</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/kafka/"><span class="tag">Kafka</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ner/"><span class="tag">NER</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/resnet/"><span class="tag">ResNet</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/sequence/"><span class="tag">Sequence</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/spark/"><span class="tag">Spark</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/spatial-temporal/"><span class="tag">Spatial-temporal</span><span class="tag is-grey-lightest">15</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/time-series/"><span class="tag">Time Series</span><span class="tag is-grey-lightest">12</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/algorithms/"><span class="tag">algorithms</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/computer-vision/"><span class="tag">computer vision</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/dataset/"><span class="tag">dataset</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag is-grey-lightest">42</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/graph-convolutional-network/"><span class="tag">graph convolutional network</span><span class="tag is-grey-lightest">20</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/image-style-transfer/"><span class="tag">image style transfer</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/implicit-feedback/"><span class="tag">implicit feedback</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/language-modeling/"><span class="tag">language modeling</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/large-scale-learning/"><span class="tag">large-scale learning</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag is-grey-lightest">19</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/machine-translation/"><span class="tag">machine translation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/natural-language-processing/"><span class="tag">natural language processing</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/normalization/"><span class="tag">normalization</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/recommender-system/"><span class="tag">recommender system</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/seq2seq/"><span class="tag">seq2seq</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/software/"><span class="tag">software</span><span class="tag is-grey-lightest">16</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/softwares/"><span class="tag">softwares</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/super-resolution/"><span class="tag">super resolution</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/virtual-machine/"><span class="tag">virtual machine</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/vscode/"><span class="tag">vscode</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E5%B7%B2%E5%A4%8D%E7%8E%B0/"><span class="tag">已复现</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E9%9A%8F%E7%AC%94/"><span class="tag">随笔</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-05-14T04:00:28.000Z">2020-05-14</time></p><p class="title is-6"><a class="link-muted" href="/blog/2020/05/14/%E5%8D%9A%E5%AE%A2%E9%87%8D%E8%A3%85/">博客重装...</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/software/">software</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-05-13T09:07:14.000Z">2020-05-13</time></p><p class="title is-6"><a class="link-muted" href="/blog/2020/05/13/neural-collaborative-filtering/">Neural Collaborative Filtering</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-02-12T16:12:07.000Z">2020-02-13</time></p><p class="title is-6"><a class="link-muted" href="/blog/2020/02/13/%E8%AE%B0%E4%B8%80%E6%AC%A1pyspark%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%EF%BC%8Cnp-frombuffer%E7%9A%84%E4%BD%BF%E7%94%A8/">记一次pyspark性能提升，np.frombuffer的使用</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B3%E5%8F%B0/">分布式平台</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-01-03T12:18:29.000Z">2020-01-03</time></p><p class="title is-6"><a class="link-muted" href="/blog/2020/01/03/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/">Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-01-02T09:03:30.000Z">2020-01-02</time></p><p class="title is-6"><a class="link-muted" href="/blog/2020/01/02/gman-a-graph-multi-attention-network-for-traffic-prediction/">GMAN: A Graph Multi-Attention Network for Traffic Prediction</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/02/"><span class="level-start"><span class="level-item">February 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/01/"><span class="level-start"><span class="level-item">January 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/12/"><span class="level-start"><span class="level-item">December 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/11/"><span class="level-start"><span class="level-item">November 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/08/"><span class="level-start"><span class="level-item">August 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/07/"><span class="level-start"><span class="level-item">July 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/06/"><span class="level-start"><span class="level-item">June 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/05/"><span class="level-start"><span class="level-item">May 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/04/"><span class="level-start"><span class="level-item">April 2019</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/03/"><span class="level-start"><span class="level-item">March 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/02/"><span class="level-start"><span class="level-item">February 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/01/"><span class="level-start"><span class="level-item">January 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/12/"><span class="level-start"><span class="level-item">December 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/10/"><span class="level-start"><span class="level-item">October 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/09/"><span class="level-start"><span class="level-item">September 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/08/"><span class="level-start"><span class="level-item">August 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/06/"><span class="level-start"><span class="level-item">June 2018</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/05/"><span class="level-start"><span class="level-item">May 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/04/"><span class="level-start"><span class="level-item">April 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/03/"><span class="level-start"><span class="level-item">March 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/02/"><span class="level-start"><span class="level-item">February 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/01/"><span class="level-start"><span class="level-item">January 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2017/08/"><span class="level-start"><span class="level-item">August 2017</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/"><img src="/blog/img/logo.svg" alt="Davidham&#039;s blog" height="28"></a><p class="size-small"><span>&copy; 2022 Davidham</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://davidham3.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/blog/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>