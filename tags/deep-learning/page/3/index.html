<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: deep learning - Davidham&#039;s blog</title><meta description="Davidham的博客，写点学习笔记啥的，邮箱mengxian.sc@alibaba-inc.com"><meta property="og:type" content="blog"><meta property="og:title" content="Davidham&#039;s blog"><meta property="og:url" content="https://davidham3.github.io/"><meta property="og:site_name" content="Davidham&#039;s blog"><meta property="og:description" content="Davidham的博客，写点学习笔记啥的，邮箱mengxian.sc@alibaba-inc.com"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://davidham3.github.io/blog/img/og_image.png"><meta property="article:author" content="Davidham"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/blog/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://davidham3.github.io"},"headline":"Davidham's blog","image":["https://davidham3.github.io/blog/img/og_image.png"],"author":{"@type":"Person","name":"Davidham"},"description":"Davidham的博客，写点学习笔记啥的，邮箱mengxian.sc@alibaba-inc.com"}</script><link rel="icon" href="/blog/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/"><img src="/blog/img/logo.svg" alt="Davidham&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">Home</a><a class="navbar-item" href="/blog/archives">Archives</a><a class="navbar-item" href="/blog/categories">Categories</a><a class="navbar-item" href="/blog/tags">Tags</a><a class="navbar-item" href="/blog/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/blog/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">deep learning</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2019-01-21T07:17:52.000Z" title="2019-01-21T07:17:52.000Z">2019-01-21</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">37 minutes read (About 5547 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2019/01/21/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/">Multistep Speed Prediction on Traffic Networks: A Graph Convolutional Sequence-to-Sequence Learning Approach with Attention Mechanism</a></h1><div class="content"><p>AGC-Seq2Seq，投的是TRC。清华大学和高德地图合作的一项研究。作者采用了 GCN + Seq2Seq + Attention 的混合模型，将路网中的边构建成图中的结点，在 GCN 上做了改进，将邻接矩阵扩展到 k 阶并与一个权重矩阵相乘，类似 HA-GCN(2016)，实现了邻居信息聚合时权重的自由调整，可以处理有向图。时间关系上使用 Seq2Seq + Attention 建模，完成了北京市二环线的多步的车速预测，对比的方法中没有近几年出现的时空预测模型。</p></div><a class="article-more button is-small size-small" href="/blog/2019/01/21/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/#more">Read More</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-12-18T12:49:15.000Z" title="2018-12-18T12:49:15.000Z">2018-12-18</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">9 minutes read (About 1403 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2018/12/18/geometric-deep-learning-on-graphs-and-manifolds-using-mixture-model-cnns/">Geometric deep learning on graphs and manifolds using mixture model CNNs</a></h1><div class="content"><p>CVPR 2017. 这篇论文有点难，没看下去。。。原文链接：<a href="https://arxiv.org/abs/1611.08402.pdf">Geometric deep learning on graphs and manifolds using mixture model CNNs</a><br></p></div><a class="article-more button is-small size-small" href="/blog/2018/12/18/geometric-deep-learning-on-graphs-and-manifolds-using-mixture-model-cnns/#more">Read More</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-12-03T07:17:12.000Z" title="2018-12-03T07:17:12.000Z">2018-12-03</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">12 minutes read (About 1746 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2018/12/03/layer-normalization/">Layer Normalization</a></h1><div class="content"><p>Layer Normalization，之前看到一篇论文用了这个LN层，看一下这个怎么实现。原文链接：<a href="https://arxiv.org/abs/1607.06450.pdf">Layer Normalization</a><br></p></div><a class="article-more button is-small size-small" href="/blog/2018/12/03/layer-normalization/#more">Read More</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-10-31T13:58:41.000Z" title="2018-10-31T13:58:41.000Z">2018-10-31</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">34 minutes read (About 5150 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2018/10/31/deeper-insights-into-graph-convolutional-networks-for-semi-supervised-learning/">Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning</a></h1><div class="content"><p>AAAI 2018。这篇论文很有趣，讲的是 GCN 堆得过多了之后，效果会变差的问题。作者分析了一下为什么会变差，主要是因为 GCN 的本质实际上是对每个结点的邻居特征和自身特征做线性组合，权重和邻接矩阵相关，所以对于顶点分类问题来说，如果堆得层数多了，就会让一个结点的特征聚合越来越多邻居的特征，让大家都变得相似，从而使得类间的相似度增大，自然分类效果就差了。作者提出了两个方法解决这个问题，算训练上的 trick 吧。原文链接：<a href="https://arxiv.org/abs/1801.07606">Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning</a><br></p></div><a class="article-more button is-small size-small" href="/blog/2018/10/31/deeper-insights-into-graph-convolutional-networks-for-semi-supervised-learning/#more">Read More</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-10-08T13:28:18.000Z" title="2018-10-08T13:28:18.000Z">2018-10-08</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">28 minutes read (About 4163 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2018/10/08/dynamic-bike-reposition-a-spatio-temporal-reinforcement-learning-approach/">Dynamic Bike Reposition: A Spatio-Temporal Reinforcement Learning Approach</a></h1><div class="content"><p>KDD 2018.强化学习处理共享单车调度问题。<br></p></div><a class="article-more button is-small size-small" href="/blog/2018/10/08/dynamic-bike-reposition-a-spatio-temporal-reinforcement-learning-approach/#more">Read More</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-09-27T07:11:55.000Z" title="2018-09-27T07:11:55.000Z">2018-09-27</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">18 minutes read (About 2663 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2018/09/27/convolutional-lstm-network-a-machine-learning-approach-for-precipitation-nowcasting/">Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting</a></h1><div class="content"><p>NIPS 2015. 将 FC-LSTM 中的全连接换成了卷积，也就是将普通的权重与矩阵相乘，换成了卷积核对输入和隐藏状态的卷积，为了能捕获空间信息，将输入变成了4维的矩阵，后两维表示空间信息。两个数据集：Moving-MNIST 和 雷达云图数据集。原文链接：<a href="https://arxiv.org/abs/1506.04214">Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting</a></p></div><a class="article-more button is-small size-small" href="/blog/2018/09/27/convolutional-lstm-network-a-machine-learning-approach-for-precipitation-nowcasting/#more">Read More</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-09-17T07:22:43.000Z" title="2018-09-17T07:22:43.000Z">2018-09-17</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">23 minutes read (About 3423 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2018/09/17/large-scale-learnable-graph-convolutional-networks/">Large-Scale Learnable Graph Convolutional Networks</a></h1><div class="content"><p>KDD 2018.将图结构数据变换到网格状数据中，使用传统的一维卷积进行卷积。变换的方式是：针对每个特征的大小，对邻居结点进行排序，取这个特征前k大的数作为它邻居这列特征的k个值。如果邻居不够，那就用0来补。这样就能得到该顶点的邻居信息，组成一个矩阵，然后使用一维卷积。但是作者没说为什么非要取最大的k个数。原文链接：<a href="https://arxiv.org/abs/1808.03965?context=stat.ML">Large-Scale Learnable Graph Convolutional Networks</a><br></p></div><a class="article-more button is-small size-small" href="/blog/2018/09/17/large-scale-learnable-graph-convolutional-networks/#more">Read More</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-08-11T02:14:13.000Z" title="2018-08-11T02:14:13.000Z">2018-08-11</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">20 minutes read (About 3040 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2018/08/11/scheduled-sampling-for-sequence-prediction-with-recurrent-neural-networks/">Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks</a></h1><div class="content"><p>NIPS 2015. 在训练seq2seq的时候，比如像机器翻译，训练的时候，每个输出y，它所依据的前一个词，都是正确的。但是在预测的时候，输出的这个词依照的上一个词，是模型输出的词，无法保证是正确的，这就会造成模型的输入和预测的分布不一致，可能会造成错误的累积。本文提出了scheduled sampling来处理这个问题。原文链接：<a href="https://arxiv.org/abs/1506.03099">Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks</a></p></div><a class="article-more button is-small size-small" href="/blog/2018/08/11/scheduled-sampling-for-sequence-prediction-with-recurrent-neural-networks/#more">Read More</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-08-03T03:06:12.000Z" title="2018-08-03T03:06:12.000Z">2018-08-03</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">43 minutes read (About 6385 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2018/08/03/the-emerging-field-of-signal-processing-on-graphs/">The Emerging Field of Signal Processing on Graphs</a></h1><div class="content"><p>IEEE Signal Processing Magazine 2013, 原文链接：<a href="https://arxiv.org/abs/1211.0053">The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains</a><br></p></div><a class="article-more button is-small size-small" href="/blog/2018/08/03/the-emerging-field-of-signal-processing-on-graphs/#more">Read More</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-07-31T06:37:10.000Z" title="2018-07-31T06:37:10.000Z">2018-07-31</time><span class="level-item"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></span><span class="level-item">42 minutes read (About 6314 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2018/07/31/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/">Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</a></h1><div class="content"><p>ICLR 2018，DCRNN，模型借鉴了<a href="https://davidham3.github.io/blog/2018/07/23/structured-sequence-modeling-with-graph-convolutional-recurrent-networks/">Structured Sequence Modeling With Graph Convolutional Recurrent Networks (ICLR 2017 reject)</a>里面的DCRNN，将该模型应用于了交通预测上。而且后者的论文使用的卷积是Defferrard提出的图卷积，这篇论文中使用的是扩散卷积，这种扩散卷积使用的是随机游走，与<a href="https://davidham3.github.io/blog/2018/07/19/diffusion-convolutional-neural-networks/">Diffusion-Convolutional Neural Networks (NIPS 2016)</a>的扩散卷积还不一样。构造出来的DCRNN使用了<a href="https://davidham3.github.io/blog/2018/07/23/structured-sequence-modeling-with-graph-convolutional-recurrent-networks/">Structured Sequence Modeling With Graph Convolutional Recurrent Networks (ICLR 2017 reject)</a>两种形式中的模型2，即使用扩散卷积学习出空间表示后，放入GRU中进行时间上的建模。原文链接：<a href="http://arxiv.org/abs/1707.01926">Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</a><br></p></div><a class="article-more button is-small size-small" href="/blog/2018/07/31/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/#more">Read More</a></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/blog/tags/deep-learning/page/2/">Previous</a></div><div class="pagination-next"><a href="/blog/tags/deep-learning/page/4/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/blog/tags/deep-learning/">1</a></li><li><a class="pagination-link" href="/blog/tags/deep-learning/page/2/">2</a></li><li><a class="pagination-link is-current" href="/blog/tags/deep-learning/page/3/">3</a></li><li><a class="pagination-link" href="/blog/tags/deep-learning/page/4/">4</a></li><li><a class="pagination-link" href="/blog/tags/deep-learning/page/5/">5</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="/blog/img/avatar.png" alt="Davidham"></figure><p class="title is-size-4 is-block line-height-inherit">Davidham</p><p class="is-size-6 is-block">阿里菜鸟-时空数据挖掘-算法工程师</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hangzhou</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/blog/archives"><p class="title">86</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/blog/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/blog/tags"><p class="title">37</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/davidham3" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/davidham3"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="mail" href="mailto:mengxian.sc@alibaba-inc.com"><i class="fa fa-envelope"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/blog/categories/algorithms/"><span class="level-start"><span class="level-item">algorithms</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/dataset/"><span class="level-start"><span class="level-item">dataset</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B3%E5%8F%B0/"><span class="level-start"><span class="level-item">分布式平台</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">自然语言处理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">论文阅读笔记</span></span><span class="level-end"><span class="level-item tag">51</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/categories/%E9%9A%8F%E7%AC%94/"><span class="level-start"><span class="level-item">随笔</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/blog/tags/attention/"><span class="tag">Attention</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/graph/"><span class="tag">Graph</span><span class="tag is-grey-lightest">27</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/hadoop/"><span class="tag">Hadoop</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/kafka/"><span class="tag">Kafka</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ner/"><span class="tag">NER</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/resnet/"><span class="tag">ResNet</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/sequence/"><span class="tag">Sequence</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/spark/"><span class="tag">Spark</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/spatial-temporal/"><span class="tag">Spatial-temporal</span><span class="tag is-grey-lightest">15</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/time-series/"><span class="tag">Time Series</span><span class="tag is-grey-lightest">12</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/algorithms/"><span class="tag">algorithms</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/computer-vision/"><span class="tag">computer vision</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/dataset/"><span class="tag">dataset</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag is-grey-lightest">49</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/event-sequence/"><span class="tag">event sequence</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/graph-convolutional-network/"><span class="tag">graph convolutional network</span><span class="tag is-grey-lightest">20</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/image-style-transfer/"><span class="tag">image style transfer</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/implicit-feedback/"><span class="tag">implicit feedback</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/language-modeling/"><span class="tag">language modeling</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/large-scale-learning/"><span class="tag">large-scale learning</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/learning-representations/"><span class="tag">learning representations</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag is-grey-lightest">19</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/machine-translation/"><span class="tag">machine translation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/natural-language-processing/"><span class="tag">natural language processing</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/normalization/"><span class="tag">normalization</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/point-process/"><span class="tag">point process</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/recommender-system/"><span class="tag">recommender system</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/seq2seq/"><span class="tag">seq2seq</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/software/"><span class="tag">software</span><span class="tag is-grey-lightest">16</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/softwares/"><span class="tag">softwares</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/super-resolution/"><span class="tag">super resolution</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/time-series/"><span class="tag">time series</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/virtual-machine/"><span class="tag">virtual machine</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/vscode/"><span class="tag">vscode</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E5%B7%B2%E5%A4%8D%E7%8E%B0/"><span class="tag">已复现</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E9%9A%8F%E7%AC%94/"><span class="tag">随笔</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2022-05-23T15:27:10.000Z">2022-05-23</time></p><p class="title is-6"><a class="link-muted" href="/blog/2022/05/23/semi-supervised-learning-for-marked-temporal-point-processes/">Semi-supervised Learning for Marked Temporal Point Processes</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2022-05-20T15:35:04.000Z">2022-05-20</time></p><p class="title is-6"><a class="link-muted" href="/blog/2022/05/20/individual-mobility-prediction-via-attentive-marked-temporal-point-processes/">Individual Mobility Prediction via Attentive Marked Temporal Point Processes</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2022-05-19T14:54:43.000Z">2022-05-19</time></p><p class="title is-6"><a class="link-muted" href="/blog/2022/05/19/unsupervised-scalable-representation-learning-for-multivariate-time-series/">Unsupervised Scalable Representation Learning for Multivariate Time Series</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2022-05-17T13:11:14.000Z">2022-05-17</time></p><p class="title is-6"><a class="link-muted" href="/blog/2022/05/17/fully-neural-network-based-model-for-general-temporal-point-processes/">Fully Neural Network based Model for General Temporal Point Processes</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2022-05-01T09:18:43.000Z">2022-05-01</time></p><p class="title is-6"><a class="link-muted" href="/blog/2022/05/01/recurrent-marked-temporal-point-processes-embedding-event-history-to-vector/">Recurrent Marked Temporal Point Processes: Embedding Event History to Vector</a></p><p class="is-uppercase"><a class="link-muted" href="/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/blog/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/02/"><span class="level-start"><span class="level-item">February 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2020/01/"><span class="level-start"><span class="level-item">January 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/12/"><span class="level-start"><span class="level-item">December 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/11/"><span class="level-start"><span class="level-item">November 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/08/"><span class="level-start"><span class="level-item">August 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/07/"><span class="level-start"><span class="level-item">July 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/06/"><span class="level-start"><span class="level-item">June 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/05/"><span class="level-start"><span class="level-item">May 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/04/"><span class="level-start"><span class="level-item">April 2019</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/03/"><span class="level-start"><span class="level-item">March 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/02/"><span class="level-start"><span class="level-item">February 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2019/01/"><span class="level-start"><span class="level-item">January 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/12/"><span class="level-start"><span class="level-item">December 2018</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/10/"><span class="level-start"><span class="level-item">October 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/09/"><span class="level-start"><span class="level-item">September 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/08/"><span class="level-start"><span class="level-item">August 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/06/"><span class="level-start"><span class="level-item">June 2018</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/05/"><span class="level-start"><span class="level-item">May 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/04/"><span class="level-start"><span class="level-item">April 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/03/"><span class="level-start"><span class="level-item">March 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/02/"><span class="level-start"><span class="level-item">February 2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2018/01/"><span class="level-start"><span class="level-item">January 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/blog/archives/2017/08/"><span class="level-start"><span class="level-item">August 2017</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/"><img src="/blog/img/logo.svg" alt="Davidham&#039;s blog" height="28"></a><p class="size-small"><span>&copy; 2022 Davidham</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://davidham3.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/blog/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>